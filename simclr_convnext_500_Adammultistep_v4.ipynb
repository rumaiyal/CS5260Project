{"cells":[{"cell_type":"markdown","metadata":{"id":"HptO0CSwNjie"},"source":["# Contrastive Learning on CIFAR10 using ConvNext Backbone"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIWaDsVYG4OH","outputId":"3e49b698-5a01-4b22-9211-7a928f5c1f9c","executionInfo":{"status":"ok","timestamp":1652837752647,"user_tz":-480,"elapsed":19793,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_fn2V83Bjj1F","executionInfo":{"status":"ok","timestamp":1652837752647,"user_tz":-480,"elapsed":5,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["#Version 4\n","#Max LR=1/10*lr corresponding to min loss\n","#Min LR=1/10 max lr or lr before min gradient of trg loss.... whichever lr is larger"]},{"cell_type":"markdown","metadata":{"id":"vXC8nEmxOMN6"},"source":["First, we import the dataset and define transformation operations on it. We apply random transformation on images (crop + flip + colorjitter + grayscale)."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"c61bUj3dVpYD","executionInfo":{"status":"ok","timestamp":1652837755518,"user_tz":-480,"elapsed":2874,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["from PIL import Image\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR10\n","import torch\n","\n","class CIFAR10Pair(CIFAR10):\n","    \"\"\"CIFAR10 Dataset.\n","    \"\"\"\n","\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            pos_1 = self.transform(img)\n","            pos_2 = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return pos_1, pos_2, target\n","\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(32),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n","    transforms.RandomGrayscale(p=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nj9DQ1-mt7Sw","outputId":"e3f4b44f-dfd1-4b10-f120-184286c1663e","executionInfo":{"status":"ok","timestamp":1652837770271,"user_tz":-480,"elapsed":14764,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running in Colab.\n","Collecting timm==0.5.4\n","  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n","\u001b[K     |████████████████████████████████| 431 kB 14.6 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.5.4) (0.12.0+cu113)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.5.4) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.5.4) (4.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.5.4) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.5.4) (2.23.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.5.4) (7.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.5.4) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.5.4) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.5.4) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.5.4) (2.10)\n","Installing collected packages: timm\n","Successfully installed timm-0.5.4\n","device =  cuda\n"]}],"source":["# check whether run in Colab\n","import sys\n","if 'google.colab' in sys.modules:\n","    print('Running in Colab.')\n","    !pip3 install timm==0.5.4 \n","\n","from timm import create_model\n","\n","\n","model_name = \"convnext_small\"\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"device = \", device)\n","# create a ConvNeXt model : https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/convnext.py\n","convnext_model = create_model(model_name, pretrained=False).to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Y13jw4ot9sp","outputId":"f157f3d6-5f70-4177-871a-43cf002189c1","executionInfo":{"status":"ok","timestamp":1652837770272,"user_tz":-480,"elapsed":9,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n","  (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n",")"]},"metadata":{},"execution_count":5}],"source":["# convnext_model.stem[0] = torch.nn.Conv2d(3, 96, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","convnext_model.head = convnext_model.head[0:3]\n","convnext_model.head"]},{"cell_type":"markdown","metadata":{"id":"ct01fnfSNHuT"},"source":["We use commonly used ResNet-50 as ConvNet encoders for simplicity in the original paper. The task 1 is to set encoder and projection head. The parameters are adapted from the original paper."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZbjYxzrgG6rO","executionInfo":{"status":"ok","timestamp":1652837770272,"user_tz":-480,"elapsed":7,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","#from torchvision.models.resnet import resnet50\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, feature_dim=128):\n","        super(Model, self).__init__()\n","\n","        self.f = []\n","        for name, module in convnext_model.named_children():\n","            # if name == 'conv1':\n","            #     module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","            # if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n","            self.f.append(module)\n","        # ----------------------------------------------------------------------\n","        # START OF YOUR CODE\n","        # ----------------------------------------------------------------------\n","        # Task 1\n","        # set a neural network base encoder self.f\n","        # hint: nn.Sequential\n","\n","        self.f = nn.Sequential(*self.f)\n","\n","        # set a small neural network projection head\n","        # Dense-> Relu-> Dense (2-layer MLP to project the representation to a 128-dimensional latent space and \n","        # the representation is 2048-dimensional here)\n","\n","        self.g = nn.Sequential(nn.Linear(768, 1000, bias=True), \n","                               nn.GELU(), \n","                               nn.Linear(1000, feature_dim, bias=True))\n","        \n","        # ----------------------------------------------------------------------\n","        # END OF YOUR CODE\n","        # ----------------------------------------------------------------------\n","    def forward(self, x):\n","        x = self.f(x)\n","        feature = torch.flatten(x, start_dim=1)\n","        out = self.g(feature)\n","        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n"]},{"cell_type":"markdown","metadata":{"id":"PPM5hsulQ74i"},"source":["We train encoder network and projection head to maximize agreement using a contrastive loss. The default epoch is 1 for time efficiency while it could takes about 10 minutes to run for one epoch in google colab. The task 2 is to calculate the contrastive loss.\n","To evaluate the influence of temperature value for contrastive loss, we run this training process 3 times with different temperature value (0.1,0.5 and 1.0)."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7FrLDw2HAWN","outputId":"ba5200de-d03f-4912-c117-4d0a991eca7b","executionInfo":{"status":"ok","timestamp":1652837773238,"user_tz":-480,"elapsed":2972,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from thop) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->thop) (4.2.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.0.31.post2005241907\n"]}],"source":["import argparse\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.optim as optim\n","!pip install thop\n","from thop import profile, clever_format\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","\n","import math\n","\n","def contrastive_loss(out_1, out_2, temperature):\n","\n","    # ------------------------------------------------------------------\n","    # START OF YOUR CODE\n","    # ------------------------------------------------------------------\n","    # Task2: implement contrastive loss function and return loss variable\n","    # hint: loss formula could refer to the slides\n","    # input: out_1, out_2，temperature\n","    # output: loss variable\n","\n","    out = torch.cat([out_1, out_2], dim=0)\n","    # [2*B, 2*B]\n","    sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n","    mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n","    # [2*B, 2*B-1]\n","    sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n","\n","    # compute loss\n","    pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n","    # [2*B]\n","    pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n","    loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean() \n","\n","    # ------------------------------------------------------------------\n","    # END OF YOUR CODE\n","    # ------------------------------------------------------------------\n","\n","    return loss\n","\n","# train for one epoch to learn unique features\n","def train(net, data_loader, train_optimizer, temperature):\n","    net.train()\n","    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n","    for pos_1, pos_2, target in train_bar:\n","        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n","        feature_1, out_1 = net(pos_1)\n","        feature_2, out_2 = net(pos_2)\n","\n","        loss = contrastive_loss(out_1, out_2, temperature)\n","\n","        train_optimizer.zero_grad()\n","        loss.backward()\n","        train_optimizer.step()\n","        #train_scheduler.step()\n","\n","        total_num += batch_size\n","        total_loss += loss.item() * batch_size\n","        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n","\n","    return total_loss / total_num\n","\n","\n","# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n","def test(net, memory_data_loader, test_data_loader, temperature):\n","    net.eval()\n","    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n","    with torch.no_grad():\n","        # generate feature bank\n","        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n","            feature, out = net(data.cuda(non_blocking=True))\n","            feature_bank.append(feature)\n","        # [D, N]\n","        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n","        # [N]\n","        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n","        # loop test data to predict the label by weighted knn search\n","        test_bar = tqdm(test_data_loader)\n","        for data, _, target in test_bar:\n","            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n","            feature, out = net(data)\n","\n","            total_num += data.size(0)\n","            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n","            sim_matrix = torch.mm(feature, feature_bank)\n","            # [B, K]\n","            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n","            # [B, K]\n","            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n","            sim_weight = (sim_weight / temperature).exp()\n","\n","            # counts for each class\n","            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n","            # [B*K, C]\n","            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n","            # weighted score ---> [B, C]\n","            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n","\n","            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n","            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n","            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n","                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n","\n","    return total_top1 / total_num * 100, total_top5 / total_num * 100"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5nhS6egtxDk8","executionInfo":{"status":"ok","timestamp":1652837773240,"user_tz":-480,"elapsed":15,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c08bb0478daf4efeaf8634c296ac0467","110d5cfae2e042918a8a5aa80315a42c","035ab878073546efbf482b1b21282f9d","c9483837485d4b888bd1949dd9238ab4","adc324540b5f4adc9614b1b6a4b7d2e5","a9b9c877d0134d57b92299a4bf09ef07","f7d32a0af8a84627af97dc0dabfcba49","ae04185aaff14f5fa1130813a07c2959","0e3516aa96ce46a1b2a66d3f9512610b","4cdff012da2f4190acc8992f9cb0abdf","118b5c75ee8e4dccb7ac9b1647b04481"]},"id":"BCIhOUGGxT93","outputId":"76630f65-49c5-4fd5-ea27-c4315da7c669","scrolled":false,"executionInfo":{"status":"error","timestamp":1652838206149,"user_tz":-480,"elapsed":432921,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08bb0478daf4efeaf8634c296ac0467"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-10-python.tar.gz to data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'timm.models.convnext.LayerNorm2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.linear.Identity'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.normalization.LayerNorm'>. Treat it as zero Macs and zero Params.\u001b[00m\n","[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.GELU'>. Treat it as zero Macs and zero Params.\u001b[00m\n","[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'timm.models.layers.mlp.Mlp'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'timm.models.convnext.ConvNeXtBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'timm.models.convnext.ConvNeXtStage'>. Treat it as zero Macs and zero Params.\u001b[00m\n","[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n","\u001b[91m[WARN] Cannot find rule for <class 'timm.models.layers.adaptive_avgmax_pool.SelectAdaptivePool2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.flatten.Flatten'>. Treat it as zero Macs and zero Params.\u001b[00m\n","\u001b[91m[WARN] Cannot find rule for <class '__main__.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/thop/vision/basic_hooks.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  kernel = torch.DoubleTensor([*(x[0].shape[2:])]) // torch.DoubleTensor(list((m.output_size,))).squeeze()\n"]},{"output_type":"stream","name":"stdout","text":["# Model Params: 50.31M FLOPs: 178.18M\n","[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330]\n"]},{"output_type":"stream","name":"stderr","text":["Train Epoch: [1/500] Loss: 4.2601: 100%|██████████| 390/390 [02:06<00:00,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.0003375\n","tensor(4.2601)\n"]},{"output_type":"stream","name":"stderr","text":["Feature extracting: 100%|██████████| 391/391 [00:23<00:00, 16.81it/s]\n","Test Epoch: [1/500] Acc@1:47.07% Acc@5:91.53%: 100%|██████████| 79/79 [00:05<00:00, 13.50it/s]\n","Train Epoch: [2/500] Loss: 3.6874: 100%|██████████| 390/390 [01:57<00:00,  3.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0.0003375\n","tensor(3.7160)\n"]},{"output_type":"stream","name":"stderr","text":["Feature extracting: 100%|██████████| 391/391 [00:23<00:00, 16.79it/s]\n","Test Epoch: [2/500] Acc@1:49.41% Acc@5:92.35%: 100%|██████████| 79/79 [00:05<00:00, 13.56it/s]\n","Train Epoch: [3/500] Loss: 3.3689:  90%|█████████ | 351/390 [01:51<00:12,  3.15it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-109425e8c18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mtrain_loss_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-4b8f40a5278a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, train_optimizer, temperature)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpos_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mfeature_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mfeature_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrastive_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-65e16211743f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train SimCLR\n","import numpy as np\n","   \n","# Feature dim for latent vector, Temperature used in softmax, Top k most similar images used to predict the label\n","feature_dim, temp, k = 128, [0.1], 200\n","# Number of images in each mini-batch, Number of sweeps over the dataset to train\n","batch_size=128\n","max_lrvalue=3.375e-4 #Rule of Thumb is peaklr (from lambdalr test)*3/8\n","min_lrvalue=2.0e-5\n","epochs=500\n","numsteps=np.max([epochs*0.67/5,10]).astype(int) \n","temp0 = 0.1 #contrastive loss temperature setting\n","schedulertype='multisteplr' #'multisteplr' for actual training\n","if schedulertype=='multisteplr':\n","    str1=str(min_lrvalue)\n","    str2=str(max_lrvalue)\n","    str3=str(numsteps)\n","    #epochs=3\n","else:\n","    print('choose valid option for scheduler')\n","smoothfactor=0.95 #Smooth Factor for smoothing contrastive loss    \n","IterationStr='It1'\n","loadmodel=0 #loadmodel=0 From scratch or loadmodel=1 Continue from presaved model \n","pathtosavemodel='/content/gdrive/MyDrive/CS5260Project/results/Simclr_convnext_Adamv4'+schedulertype+'_minlr_'+str1+'_maxlr_'+str2+'_numsteps_'+str3+'/'+IterationStr+'/model/'\n","pathtosavecsv='/content/gdrive/MyDrive/CS5260Project/results/Simclr_convnext_Adamv4'+schedulertype+'_minlr_'+str1+'_maxlr_'+str2+'_numsteps_'+str3+'/'+IterationStr+'/csv/'\n","save_name_pre = '{}_{}_{}_{}_{}'.format(feature_dim, temp0, k, batch_size, epochs)\n","csvfilename=pathtosavecsv+'{}_statistics.csv'.format(save_name_pre)\n","modelfilename=pathtosavemodel+'{}_model.pth'.format(save_name_pre)\n","\n","# data prepare\n","train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True,\n","                          drop_last=True)\n","memory_data = CIFAR10Pair(root='data', train=True, transform=test_transform, download=True)\n","memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n","test_data = CIFAR10Pair(root='data', train=False, transform=test_transform, download=True)\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n","\n","import torch\n","n=2\n","torch.cuda.is_available()\n","#torch.cuda.set_device(n)\n","\n","# model setup and optimizer config\n","model = Model(feature_dim).cuda()\n","\n","\n","flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n","flops, params = clever_format([flops, params])\n","print('# Model Params: {} FLOPs: {}'.format(params, flops))\n","\n","optimizer = optim.Adam(model.parameters(), weight_decay=1e-6, lr=max_lrvalue)\n","if schedulertype=='multisteplr':\n","   gammaval=2**(math.log2(min_lrvalue/max_lrvalue)/numsteps)\n","   milestones_list=np.rint(np.arange(0,numsteps)/numsteps*epochs*0.67)[1:].astype(int).tolist() \n","   print(milestones_list)\n","   scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=milestones_list,gamma=gammaval)\n","else:\n","   print('choose valid option for scheduler')\n","\n","\n","if loadmodel==1:\n","   checkpoint=torch.load(modelfilename)\n","   model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n","   model.to(device)\n","   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","   scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","   startepoch=checkpoint['epoch']+1\n","   best_acc=checkpoint['best_acc']\n","\n","   print(startepoch)\n","else:     \n","   startepoch=1\n","   best_acc=0\n","   \n","\n","c = len(memory_data.classes)\n","\n","if not os.path.exists(pathtosavemodel):\n","   os.makedirs(pathtosavemodel)\n","if not os.path.exists(pathtosavecsv):\n","   os.makedirs(pathtosavecsv)\n","\n","train_loss_epoch=torch.zeros(epochs)\n","smooth_loss_epoch=torch.zeros(epochs)\n","test_acc_1_epoch=torch.zeros(epochs)\n","test_acc_5_epoch=torch.zeros(epochs)\n","lr_epoch=torch.zeros(epochs)\n","\n","if loadmodel==1:\n","\n","   df=pd.read_csv(csvfilename)\n","   temp=pd.to_numeric(df.iloc[0:startepoch-1,1]).apply(np.array)\n","   train_loss_epoch[0:temp.size]=torch.tensor(temp)\n","   train_loss_list=temp.tolist()\n","   temp=pd.to_numeric(df.iloc[0:startepoch-1,2]).apply(np.array)\n","   test_acc_1_epoch[0:temp.size]=torch.tensor(temp)\n","   test_acc_1_list=temp.tolist()\n","   temp=pd.to_numeric(df.iloc[0:startepoch-1,3]).apply(np.array)\n","   test_acc_5_epoch[0:temp.size]=torch.tensor(temp)\n","   test_acc_5_list=temp.tolist()\n","   temp=pd.to_numeric(df.iloc[0:startepoch-1,4]).apply(np.array)\n","   smooth_loss_epoch[0:temp.size]=torch.tensor(temp)\n","   smooth_loss_list=temp.tolist()\n","   temp=pd.to_numeric(df.iloc[0:startepoch-1,5]).apply(np.array)\n","   lr_epoch[0:temp.size]=torch.tensor(temp)\n","   lr_list=temp.tolist()\n","   results = {'train_loss': train_loss_list, 'test_acc@1': test_acc_1_list, 'test_acc@5': test_acc_5_list, 'smooth_loss': smooth_loss_list, 'lr_epoch': lr_list}\n","\n","else:\n","   results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': [], 'smooth_loss': [], 'lr_epoch': []}\n","\n","\n","for epoch in range(startepoch, epochs + 1):\n","        \n","    train_loss = train(model, train_loader, optimizer, temp0)\n","    scheduler.step()\n","    train_loss_epoch[epoch-1]=train_loss\n","    if epoch>1:\n","       smooth_loss=float(train_loss_epoch[epoch-1]*smoothfactor+smooth_loss_epoch[epoch-2]*(1.0-smoothfactor))\n","    else:\n","       smooth_loss=train_loss\n","    smooth_loss_epoch[epoch-1]=torch.tensor(smooth_loss)\n","\n","\n","    print(optimizer.param_groups[0]['lr'])\n","    print(smooth_loss_epoch[epoch-1])\n","    lr_epoch[epoch-1]=float(optimizer.param_groups[0]['lr'])\n","   \n","        \n","    results['train_loss'].append(train_loss)\n","    test_acc_1, test_acc_5 = test(model, memory_loader, test_loader, temp0)\n","    results['test_acc@1'].append(test_acc_1)\n","    results['test_acc@5'].append(test_acc_5)\n","    results['smooth_loss'].append(smooth_loss)\n","    results['lr_epoch'].append(optimizer.param_groups[0]['lr'])\n","   \n","    # save statistics\n","    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n","    data_frame.to_csv(csvfilename, index_label='epoch')\n","    if test_acc_1 > best_acc:\n","        best_acc = test_acc_1\n","        torch.save({'epoch':epoch,'model_state_dict':model.state_dict(),'optimizer_state_dict':optimizer.state_dict(),'scheduler_state_dict':scheduler.state_dict(),'best_acc':best_acc}, modelfilename)\n","    test_acc_1_epoch[epoch-1]=test_acc_1\n","    test_acc_5_epoch[epoch-1]=test_acc_5\n","    \n","minloss_loc=torch.argmin(smooth_loss_epoch)\n","minloss_lr=lr_epoch[minloss_loc]\n","maxgradloss_loc=torch.argmin(torch.gradient(smooth_loss_epoch)[0])\n","maxgradloss_lr=lr_epoch[maxgradloss_loc]\n","initfactor=1/10\n","maxfactor=1/10\n","print(f'lr corresponding to minloss={minloss_lr}');\n","print(f'lr corresponding to max grad={maxgradloss_lr}');\n","print(f'suggested maxlr={minloss_lr*maxfactor}');\n","print(f'suggested minlr={max(minloss_lr*initfactor*maxfactor,maxgradloss_lr)}');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kc2fmSbpO0Po","executionInfo":{"status":"aborted","timestamp":1652838206144,"user_tz":-480,"elapsed":43,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","df=pd.read_csv(csvfilename)\n","\n","f1=plt.figure()\n","plt.semilogx(df['lr_epoch'],df['smooth_loss'])  \n","plt.xlabel('learning rate')\n","plt.ylabel('smoothed trg epoch loss')\n","plt.show()\n","\n","f2=plt.figure()\n","plt.semilogx(df['lr_epoch'],df['test_acc@1'])\n","plt.title('Sim CLR with RAdam')\n","plt.xlabel('learning rate')\n","plt.ylabel('epoch Test Accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re2jYqmfjj1Y","executionInfo":{"status":"aborted","timestamp":1652838206145,"user_tz":-480,"elapsed":42,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["print(f'lr corresponding to minloss={minloss_lr}');\n","print(f'lr corresponding to max grad={maxgradloss_lr}');\n","print(f'suggested maxlr={minloss_lr*maxfactor}');\n","print(f'suggested minlr={max(minloss_lr*initfactor*maxfactor,maxgradloss_lr)}');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0E1ySUIjj1a","executionInfo":{"status":"aborted","timestamp":1652838206146,"user_tz":-480,"elapsed":43,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["smooth_loss_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kosFh8fpjj1a","executionInfo":{"status":"aborted","timestamp":1652838206146,"user_tz":-480,"elapsed":42,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["torch.gradient(smooth_loss_epoch)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgjAW9eGjj1b","executionInfo":{"status":"aborted","timestamp":1652838206147,"user_tz":-480,"elapsed":43,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["smooth_loss_epoch.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDp0P_urjj1b","executionInfo":{"status":"aborted","timestamp":1652838206148,"user_tz":-480,"elapsed":43,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["maxgradloss_lr=lr_epoch[maxgradloss_loclr]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpI5d6qljj1c","executionInfo":{"status":"aborted","timestamp":1652838206148,"user_tz":-480,"elapsed":43,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":["maxgradloss_lr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEkGrwvGjj1c","executionInfo":{"status":"aborted","timestamp":1652838206149,"user_tz":-480,"elapsed":44,"user":{"displayName":"Umaiyal Ramanathan","userId":"12104065804675727870"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"simclr_convnext_500_Adammultistep_v4.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c08bb0478daf4efeaf8634c296ac0467":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_110d5cfae2e042918a8a5aa80315a42c","IPY_MODEL_035ab878073546efbf482b1b21282f9d","IPY_MODEL_c9483837485d4b888bd1949dd9238ab4"],"layout":"IPY_MODEL_adc324540b5f4adc9614b1b6a4b7d2e5"}},"110d5cfae2e042918a8a5aa80315a42c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9b9c877d0134d57b92299a4bf09ef07","placeholder":"​","style":"IPY_MODEL_f7d32a0af8a84627af97dc0dabfcba49","value":""}},"035ab878073546efbf482b1b21282f9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae04185aaff14f5fa1130813a07c2959","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e3516aa96ce46a1b2a66d3f9512610b","value":170498071}},"c9483837485d4b888bd1949dd9238ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cdff012da2f4190acc8992f9cb0abdf","placeholder":"​","style":"IPY_MODEL_118b5c75ee8e4dccb7ac9b1647b04481","value":" 170499072/? [00:05&lt;00:00, 31616244.36it/s]"}},"adc324540b5f4adc9614b1b6a4b7d2e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9b9c877d0134d57b92299a4bf09ef07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d32a0af8a84627af97dc0dabfcba49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae04185aaff14f5fa1130813a07c2959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3516aa96ce46a1b2a66d3f9512610b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cdff012da2f4190acc8992f9cb0abdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"118b5c75ee8e4dccb7ac9b1647b04481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}