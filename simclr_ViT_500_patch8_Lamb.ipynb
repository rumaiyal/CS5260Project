{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "buoggcs5SZCZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HptO0CSwNjie"
      },
      "source": [
        "# ViT Implementation of SimClr with Assignment 5 base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkIokoYtNI_G"
      },
      "source": [
        "Please submit this file to Luminus by **23:59 on 20 Mar**. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Finish 2 tasks according to the instructions. Only change the code in the required area and DO NOT change others or add new code/text snippets.\n",
        "2. Rename this file as \"Student_number.ipynb\". e.g., 'A0000000J.ipynb'. \n",
        "\n",
        "3. Submit the file to /Files/assignments/submission/assignment5. \n",
        "\n",
        "Please follow the instructions strictly, otherwise you might be penalized.\n",
        "\n",
        "If you has any questions, please propose it on Slack, or contact Ziheng Qin (e0823059@u.nus.edu) and Yong Liu (e0672130@u.nus.edu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXC8nEmxOMN6"
      },
      "source": [
        "First, we import the dataset and define transformation operations on it. We apply random transformation on images (crop + flip + colorjitter + grayscale)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ec72b5-6ab6-4c58-bf13-d7c34168db4a",
        "id": "Oy5_kIwxu2im"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!HOROVOD_WITH_PYTORCH=1 pip install horovod[pytorch]"
      ],
      "metadata": {
        "id": "wW8j-Guvu4_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Need to install upgraded torch and torchvision to access vit models\n",
        "#!pip install --upgrade torch torchvision\n"
      ],
      "metadata": {
        "id": "EdbBiFztPPZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIWaDsVYG4OH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "class CIFAR10Pair(CIFAR10):\n",
        "    \"\"\"CIFAR10 Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            pos_1 = self.transform(img)\n",
        "            pos_2 = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return pos_1, pos_2, target\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct01fnfSNHuT"
      },
      "source": [
        "Copied over Vision Transformer code in cell below from SiT project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFj_MFx3j-jn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJw7ten1-mB"
      },
      "source": [
        "Simple ViT implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us-QsNIb4uZp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpttG9-O15ma"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2u7vQQ14wTe",
        "outputId": "de574f08-0dd9-485e-f3fc-3a5d6c9b92e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# self written ViT code\n",
        "# referenced from https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n",
        "\n",
        "!pip install einops\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "# helpers\n",
        "\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "# classes\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim = -1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
        "            ]))\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size=32, patch_size=8, num_classes=1000, dim=1024, depth=6, heads=16, mlp_dim=2048, pool = 'cls', channels = 3, dim_head = 64, dropout = 0.1, emb_dropout = 0.1, feature_dim=128):\n",
        "    #def __init__(self, *, image_size=256, patch_size=16, num_classes=1000, dim=1024, depth=6, heads=16, mlp_dim=2048, pool = 'cls', channels = 3, dim_head = 64, dropout = 0.1, emb_dropout = 0.1, feature_dim=128):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "        #self.linear_crossover = nn.Linear(5120, mlp_dim)\n",
        "        self.linear_crossover = nn.Linear(17408,mlp_dim) \n",
        "\n",
        "        self.g = nn.Sequential(nn.Linear(mlp_dim, 512, bias=False), \n",
        "                               nn.BatchNorm1d(512),\n",
        "                               nn.ReLU(inplace=True),\n",
        "                               nn.Linear(512, feature_dim, bias=True))\n",
        "\n",
        "\n",
        "        #comment out below\n",
        "        #self.pool = pool\n",
        "        #self.to_latent = nn.Identity()\n",
        "        #self.mlp_head = nn.Sequential(\n",
        "        #    nn.LayerNorm(dim),\n",
        "        #    nn.Linear(dim, num_classes)\n",
        "        #)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #print(\"x input shape: \", x.shape)\n",
        "\n",
        "        x = self.to_patch_embedding(x)\n",
        "\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        #print(\"X after dropout layer: \", x.shape)\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        #print(\"X after transformer layer: \", x.shape)\n",
        "\n",
        "        x = torch.flatten(x,1)\n",
        "        #print(\"X after reduce_dim layer: \", x.shape)\n",
        "\n",
        "        x = self.linear_crossover(x)\n",
        "        #print(\"X after linear layer: \", x.shape)\n",
        "\n",
        "        feature = x\n",
        "        #print(\"F after dimension removal: \", feature.shape)\n",
        "\n",
        "        out = self.g(feature)\n",
        "        #out = feature\n",
        "        #print(\"Out Shape: \", out.shape)\n",
        "\n",
        "\n",
        "        #comment out below\n",
        "        #x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "        #x = self.to_latent(x)\n",
        "        #x = self.mlp_head(x)\n",
        "\n",
        "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssdgJe0e5mIq"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtuMgMT-kk-R"
      },
      "source": [
        "We use commonly used ResNet-50 as ConvNet encoders for simplicity in the original paper. The task 1 is to set encoder and projection head. The parameters are adapted from the original paper.\n",
        "\n",
        "\n",
        "Task is to replace the ResNet-50 with a ViT - one for one replacement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbjYxzrgG6rO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPM5hsulQ74i"
      },
      "source": [
        "We train encoder network and projection head to maximize agreement using a contrastive loss. The default epoch is 1 for time efficiency while it could takes about 10 minutes to run for one epoch in google colab. The task 2 is to calculate the contrastive loss.\n",
        "To evaluate the influence of temperature value for contrastive loss, we run this training process 3 times with different temperature value (0.1,0.5 and 1.0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w7FrLDw2HAWN",
        "outputId": "66016fd6-45d3-4469-f253-bead3cf0791e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (0.0.31.post2005241907)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from thop) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->thop) (3.10.0.2)\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/390 [00:00<?, ?it/s]/content/gdrive/MyDrive/CS5260Project/pytorch_lamb_master/optim/lamb.py:89: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
            "Train Epoch: [1/501] Loss: 4.0205: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.73it/s]\n",
            "Test Epoch: [1/501] Acc@1:47.87% Acc@5:91.78%: 100%|██████████| 79/79 [00:05<00:00, 13.23it/s]\n",
            "Train Epoch: [2/501] Loss: 3.2268: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.88it/s]\n",
            "Test Epoch: [2/501] Acc@1:49.60% Acc@5:92.80%: 100%|██████████| 79/79 [00:06<00:00, 12.82it/s]\n",
            "Train Epoch: [3/501] Loss: 2.9080: 100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.76it/s]\n",
            "Test Epoch: [3/501] Acc@1:49.76% Acc@5:92.80%: 100%|██████████| 79/79 [00:06<00:00, 12.13it/s]\n",
            "Train Epoch: [4/501] Loss: 2.6821: 100%|██████████| 390/390 [01:46<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.13it/s]\n",
            "Test Epoch: [4/501] Acc@1:50.65% Acc@5:93.47%: 100%|██████████| 79/79 [00:06<00:00, 12.41it/s]\n",
            "Train Epoch: [5/501] Loss: 2.5289: 100%|██████████| 390/390 [01:50<00:00,  3.53it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.50it/s]\n",
            "Test Epoch: [5/501] Acc@1:51.61% Acc@5:93.32%: 100%|██████████| 79/79 [00:06<00:00, 12.71it/s]\n",
            "Train Epoch: [6/501] Loss: 2.4069: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.72it/s]\n",
            "Test Epoch: [6/501] Acc@1:52.14% Acc@5:93.96%: 100%|██████████| 79/79 [00:06<00:00, 12.56it/s]\n",
            "Train Epoch: [7/501] Loss: 2.3289: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.47it/s]\n",
            "Test Epoch: [7/501] Acc@1:53.18% Acc@5:94.17%: 100%|██████████| 79/79 [00:06<00:00, 11.74it/s]\n",
            "Train Epoch: [8/501] Loss: 2.2522: 100%|██████████| 390/390 [01:48<00:00,  3.60it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.02it/s]\n",
            "Test Epoch: [8/501] Acc@1:53.55% Acc@5:94.51%: 100%|██████████| 79/79 [00:06<00:00, 12.00it/s]\n",
            "Train Epoch: [9/501] Loss: 2.1972: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.08it/s]\n",
            "Test Epoch: [9/501] Acc@1:54.66% Acc@5:94.75%: 100%|██████████| 79/79 [00:06<00:00, 12.23it/s]\n",
            "Train Epoch: [10/501] Loss: 2.1250: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s]\n",
            "Test Epoch: [10/501] Acc@1:53.60% Acc@5:94.41%: 100%|██████████| 79/79 [00:06<00:00, 12.48it/s]\n",
            "Train Epoch: [11/501] Loss: 2.1003: 100%|██████████| 390/390 [01:45<00:00,  3.71it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.95it/s]\n",
            "Test Epoch: [11/501] Acc@1:54.75% Acc@5:94.59%: 100%|██████████| 79/79 [00:06<00:00, 12.38it/s]\n",
            "Train Epoch: [12/501] Loss: 2.0531: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.10it/s]\n",
            "Test Epoch: [12/501] Acc@1:55.76% Acc@5:95.03%: 100%|██████████| 79/79 [00:06<00:00, 12.06it/s]\n",
            "Train Epoch: [13/501] Loss: 1.9871: 100%|██████████| 390/390 [01:45<00:00,  3.71it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.88it/s]\n",
            "Test Epoch: [13/501] Acc@1:55.97% Acc@5:95.16%: 100%|██████████| 79/79 [00:06<00:00, 12.54it/s]\n",
            "Train Epoch: [14/501] Loss: 1.9481: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.91it/s]\n",
            "Test Epoch: [14/501] Acc@1:56.54% Acc@5:95.19%: 100%|██████████| 79/79 [00:06<00:00, 12.46it/s]\n",
            "Train Epoch: [15/501] Loss: 1.9252: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.37it/s]\n",
            "Test Epoch: [15/501] Acc@1:56.24% Acc@5:95.57%: 100%|██████████| 79/79 [00:06<00:00, 12.60it/s]\n",
            "Train Epoch: [16/501] Loss: 1.8969: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.24it/s]\n",
            "Test Epoch: [16/501] Acc@1:56.91% Acc@5:95.47%: 100%|██████████| 79/79 [00:05<00:00, 13.37it/s]\n",
            "Train Epoch: [17/501] Loss: 1.8641: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.95it/s]\n",
            "Test Epoch: [17/501] Acc@1:57.37% Acc@5:95.52%: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s]\n",
            "Train Epoch: [18/501] Loss: 1.8372: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.77it/s]\n",
            "Test Epoch: [18/501] Acc@1:56.97% Acc@5:95.56%: 100%|██████████| 79/79 [00:06<00:00, 12.80it/s]\n",
            "Train Epoch: [19/501] Loss: 1.8221: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.96it/s]\n",
            "Test Epoch: [19/501] Acc@1:58.29% Acc@5:95.79%: 100%|██████████| 79/79 [00:06<00:00, 12.43it/s]\n",
            "Train Epoch: [20/501] Loss: 1.7933: 100%|██████████| 390/390 [01:46<00:00,  3.67it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.04it/s]\n",
            "Test Epoch: [20/501] Acc@1:58.12% Acc@5:95.70%: 100%|██████████| 79/79 [00:06<00:00, 12.70it/s]\n",
            "Train Epoch: [21/501] Loss: 1.7704: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.32it/s]\n",
            "Test Epoch: [21/501] Acc@1:59.11% Acc@5:95.93%: 100%|██████████| 79/79 [00:06<00:00, 12.55it/s]\n",
            "Train Epoch: [22/501] Loss: 1.7430: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.32it/s]\n",
            "Test Epoch: [22/501] Acc@1:58.45% Acc@5:95.63%: 100%|██████████| 79/79 [00:06<00:00, 12.94it/s]\n",
            "Train Epoch: [23/501] Loss: 1.7458: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.12it/s]\n",
            "Test Epoch: [23/501] Acc@1:59.65% Acc@5:95.99%: 100%|██████████| 79/79 [00:06<00:00, 12.72it/s]\n",
            "Train Epoch: [24/501] Loss: 1.7147: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.73it/s]\n",
            "Test Epoch: [24/501] Acc@1:59.95% Acc@5:96.26%: 100%|██████████| 79/79 [00:06<00:00, 12.58it/s]\n",
            "Train Epoch: [25/501] Loss: 1.6987: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.16it/s]\n",
            "Test Epoch: [25/501] Acc@1:59.49% Acc@5:96.43%: 100%|██████████| 79/79 [00:06<00:00, 12.40it/s]\n",
            "Train Epoch: [26/501] Loss: 1.6934: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.29it/s]\n",
            "Test Epoch: [26/501] Acc@1:59.84% Acc@5:96.21%: 100%|██████████| 79/79 [00:06<00:00, 12.61it/s]\n",
            "Train Epoch: [27/501] Loss: 1.6792: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.18it/s]\n",
            "Test Epoch: [27/501] Acc@1:60.42% Acc@5:96.27%: 100%|██████████| 79/79 [00:06<00:00, 12.59it/s]\n",
            "Train Epoch: [28/501] Loss: 1.6496: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.41it/s]\n",
            "Test Epoch: [28/501] Acc@1:60.15% Acc@5:96.31%: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s]\n",
            "Train Epoch: [29/501] Loss: 1.6480: 100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.35it/s]\n",
            "Test Epoch: [29/501] Acc@1:61.38% Acc@5:96.48%: 100%|██████████| 79/79 [00:06<00:00, 12.46it/s]\n",
            "Train Epoch: [30/501] Loss: 1.6411: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.36it/s]\n",
            "Test Epoch: [30/501] Acc@1:60.37% Acc@5:96.43%: 100%|██████████| 79/79 [00:06<00:00, 12.78it/s]\n",
            "Train Epoch: [31/501] Loss: 1.6425: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.69it/s]\n",
            "Test Epoch: [31/501] Acc@1:61.28% Acc@5:96.51%: 100%|██████████| 79/79 [00:06<00:00, 12.40it/s]\n",
            "Train Epoch: [32/501] Loss: 1.6349: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.38it/s]\n",
            "Test Epoch: [32/501] Acc@1:60.90% Acc@5:96.24%: 100%|██████████| 79/79 [00:06<00:00, 12.60it/s]\n",
            "Train Epoch: [33/501] Loss: 1.6176: 100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.26it/s]\n",
            "Test Epoch: [33/501] Acc@1:61.28% Acc@5:96.73%: 100%|██████████| 79/79 [00:06<00:00, 12.39it/s]\n",
            "Train Epoch: [34/501] Loss: 1.6114: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.63it/s]\n",
            "Test Epoch: [34/501] Acc@1:61.59% Acc@5:96.57%: 100%|██████████| 79/79 [00:06<00:00, 11.93it/s]\n",
            "Train Epoch: [35/501] Loss: 1.6002: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.89it/s]\n",
            "Test Epoch: [35/501] Acc@1:61.26% Acc@5:96.61%: 100%|██████████| 79/79 [00:06<00:00, 12.24it/s]\n",
            "Train Epoch: [36/501] Loss: 1.5922: 100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.04it/s]\n",
            "Test Epoch: [36/501] Acc@1:61.77% Acc@5:96.71%: 100%|██████████| 79/79 [00:06<00:00, 12.66it/s]\n",
            "Train Epoch: [37/501] Loss: 1.5806: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.32it/s]\n",
            "Test Epoch: [37/501] Acc@1:61.78% Acc@5:96.80%: 100%|██████████| 79/79 [00:06<00:00, 12.56it/s]\n",
            "Train Epoch: [38/501] Loss: 1.5716: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.42it/s]\n",
            "Test Epoch: [38/501] Acc@1:62.11% Acc@5:96.88%: 100%|██████████| 79/79 [00:05<00:00, 13.23it/s]\n",
            "Train Epoch: [39/501] Loss: 1.5573: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.35it/s]\n",
            "Test Epoch: [39/501] Acc@1:62.26% Acc@5:96.81%: 100%|██████████| 79/79 [00:06<00:00, 12.48it/s]\n",
            "Train Epoch: [40/501] Loss: 1.5545: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.88it/s]\n",
            "Test Epoch: [40/501] Acc@1:62.31% Acc@5:96.98%: 100%|██████████| 79/79 [00:06<00:00, 12.54it/s]\n",
            "Train Epoch: [41/501] Loss: 1.5391: 100%|██████████| 390/390 [01:43<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.30it/s]\n",
            "Test Epoch: [41/501] Acc@1:62.64% Acc@5:96.88%: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s]\n",
            "Train Epoch: [42/501] Loss: 1.5332: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.45it/s]\n",
            "Test Epoch: [42/501] Acc@1:62.91% Acc@5:96.94%: 100%|██████████| 79/79 [00:06<00:00, 12.56it/s]\n",
            "Train Epoch: [43/501] Loss: 1.5264: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.15it/s]\n",
            "Test Epoch: [43/501] Acc@1:63.11% Acc@5:96.75%: 100%|██████████| 79/79 [00:06<00:00, 12.56it/s]\n",
            "Train Epoch: [44/501] Loss: 1.5081: 100%|██████████| 390/390 [01:43<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.19it/s]\n",
            "Test Epoch: [44/501] Acc@1:62.58% Acc@5:96.65%: 100%|██████████| 79/79 [00:06<00:00, 12.49it/s]\n",
            "Train Epoch: [45/501] Loss: 1.5131: 100%|██████████| 390/390 [01:41<00:00,  3.85it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s]\n",
            "Test Epoch: [45/501] Acc@1:63.30% Acc@5:96.93%: 100%|██████████| 79/79 [00:06<00:00, 12.73it/s]\n",
            "Train Epoch: [46/501] Loss: 1.5049: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:19<00:00, 19.58it/s]\n",
            "Test Epoch: [46/501] Acc@1:63.52% Acc@5:97.03%: 100%|██████████| 79/79 [00:06<00:00, 12.34it/s]\n",
            "Train Epoch: [47/501] Loss: 1.4895: 100%|██████████| 390/390 [01:39<00:00,  3.90it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:19<00:00, 19.68it/s]\n",
            "Test Epoch: [47/501] Acc@1:63.65% Acc@5:96.90%: 100%|██████████| 79/79 [00:06<00:00, 13.00it/s]\n",
            "Train Epoch: [48/501] Loss: 1.4793: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.36it/s]\n",
            "Test Epoch: [48/501] Acc@1:63.14% Acc@5:96.79%: 100%|██████████| 79/79 [00:06<00:00, 12.58it/s]\n",
            "Train Epoch: [49/501] Loss: 1.4841: 100%|██████████| 390/390 [01:41<00:00,  3.86it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.27it/s]\n",
            "Test Epoch: [49/501] Acc@1:64.19% Acc@5:97.01%: 100%|██████████| 79/79 [00:06<00:00, 12.49it/s]\n",
            "Train Epoch: [50/501] Loss: 1.4658: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.90it/s]\n",
            "Test Epoch: [50/501] Acc@1:63.88% Acc@5:96.99%: 100%|██████████| 79/79 [00:06<00:00, 12.72it/s]\n",
            "Train Epoch: [51/501] Loss: 1.4696: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.88it/s]\n",
            "Test Epoch: [51/501] Acc@1:64.71% Acc@5:97.08%: 100%|██████████| 79/79 [00:06<00:00, 12.17it/s]\n",
            "Train Epoch: [52/501] Loss: 1.4588: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.12it/s]\n",
            "Test Epoch: [52/501] Acc@1:63.92% Acc@5:97.05%: 100%|██████████| 79/79 [00:06<00:00, 12.70it/s]\n",
            "Train Epoch: [53/501] Loss: 1.4554: 100%|██████████| 390/390 [01:41<00:00,  3.86it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.21it/s]\n",
            "Test Epoch: [53/501] Acc@1:64.94% Acc@5:97.25%: 100%|██████████| 79/79 [00:06<00:00, 12.34it/s]\n",
            "Train Epoch: [54/501] Loss: 1.4547: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.29it/s]\n",
            "Test Epoch: [54/501] Acc@1:63.82% Acc@5:97.20%: 100%|██████████| 79/79 [00:06<00:00, 12.35it/s]\n",
            "Train Epoch: [55/501] Loss: 1.4341: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.17it/s]\n",
            "Test Epoch: [55/501] Acc@1:64.44% Acc@5:97.27%: 100%|██████████| 79/79 [00:06<00:00, 12.60it/s]\n",
            "Train Epoch: [56/501] Loss: 1.4505: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.35it/s]\n",
            "Test Epoch: [56/501] Acc@1:64.84% Acc@5:97.28%: 100%|██████████| 79/79 [00:06<00:00, 12.36it/s]\n",
            "Train Epoch: [57/501] Loss: 1.4366: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.46it/s]\n",
            "Test Epoch: [57/501] Acc@1:64.56% Acc@5:97.35%: 100%|██████████| 79/79 [00:06<00:00, 12.14it/s]\n",
            "Train Epoch: [58/501] Loss: 1.4245: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.11it/s]\n",
            "Test Epoch: [58/501] Acc@1:65.54% Acc@5:97.23%: 100%|██████████| 79/79 [00:06<00:00, 12.47it/s]\n",
            "Train Epoch: [59/501] Loss: 1.4371: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.22it/s]\n",
            "Test Epoch: [59/501] Acc@1:65.12% Acc@5:97.10%: 100%|██████████| 79/79 [00:06<00:00, 12.48it/s]\n",
            "Train Epoch: [60/501] Loss: 1.4283: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.37it/s]\n",
            "Test Epoch: [60/501] Acc@1:64.92% Acc@5:97.15%: 100%|██████████| 79/79 [00:06<00:00, 12.20it/s]\n",
            "Train Epoch: [61/501] Loss: 1.4157: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s]\n",
            "Test Epoch: [61/501] Acc@1:65.25% Acc@5:97.22%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [62/501] Loss: 1.4193: 100%|██████████| 390/390 [01:41<00:00,  3.85it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.35it/s]\n",
            "Test Epoch: [62/501] Acc@1:65.86% Acc@5:97.47%: 100%|██████████| 79/79 [00:06<00:00, 12.13it/s]\n",
            "Train Epoch: [63/501] Loss: 1.4072: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.04it/s]\n",
            "Test Epoch: [63/501] Acc@1:65.31% Acc@5:97.11%: 100%|██████████| 79/79 [00:06<00:00, 12.30it/s]\n",
            "Train Epoch: [64/501] Loss: 1.3982: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.35it/s]\n",
            "Test Epoch: [64/501] Acc@1:66.36% Acc@5:97.37%: 100%|██████████| 79/79 [00:06<00:00, 12.37it/s]\n",
            "Train Epoch: [65/501] Loss: 1.3957: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.55it/s]\n",
            "Test Epoch: [65/501] Acc@1:65.68% Acc@5:97.42%: 100%|██████████| 79/79 [00:06<00:00, 11.96it/s]\n",
            "Train Epoch: [66/501] Loss: 1.4030: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.54it/s]\n",
            "Test Epoch: [66/501] Acc@1:66.58% Acc@5:97.42%: 100%|██████████| 79/79 [00:06<00:00, 11.91it/s]\n",
            "Train Epoch: [67/501] Loss: 1.3860: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.33it/s]\n",
            "Test Epoch: [67/501] Acc@1:65.89% Acc@5:97.29%: 100%|██████████| 79/79 [00:06<00:00, 11.81it/s]\n",
            "Train Epoch: [68/501] Loss: 1.3816: 100%|██████████| 390/390 [01:41<00:00,  3.85it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.24it/s]\n",
            "Test Epoch: [68/501] Acc@1:66.24% Acc@5:97.21%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [69/501] Loss: 1.3793: 100%|██████████| 390/390 [01:39<00:00,  3.92it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.38it/s]\n",
            "Test Epoch: [69/501] Acc@1:66.44% Acc@5:97.43%: 100%|██████████| 79/79 [00:06<00:00, 12.78it/s]\n",
            "Train Epoch: [70/501] Loss: 1.3789: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.96it/s]\n",
            "Test Epoch: [70/501] Acc@1:66.07% Acc@5:97.50%: 100%|██████████| 79/79 [00:06<00:00, 12.27it/s]\n",
            "Train Epoch: [71/501] Loss: 1.3711: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s]\n",
            "Test Epoch: [71/501] Acc@1:65.91% Acc@5:97.34%: 100%|██████████| 79/79 [00:06<00:00, 12.06it/s]\n",
            "Train Epoch: [72/501] Loss: 1.3684: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:19<00:00, 19.84it/s]\n",
            "Test Epoch: [72/501] Acc@1:66.15% Acc@5:97.30%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [73/501] Loss: 1.3726: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.89it/s]\n",
            "Test Epoch: [73/501] Acc@1:67.10% Acc@5:97.49%: 100%|██████████| 79/79 [00:06<00:00, 12.12it/s]\n",
            "Train Epoch: [74/501] Loss: 1.3623: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.69it/s]\n",
            "Test Epoch: [74/501] Acc@1:66.64% Acc@5:97.65%: 100%|██████████| 79/79 [00:06<00:00, 11.93it/s]\n",
            "Train Epoch: [75/501] Loss: 1.3687: 100%|██████████| 390/390 [01:41<00:00,  3.85it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.27it/s]\n",
            "Test Epoch: [75/501] Acc@1:66.23% Acc@5:97.26%: 100%|██████████| 79/79 [00:06<00:00, 12.02it/s]\n",
            "Train Epoch: [76/501] Loss: 1.3540: 100%|██████████| 390/390 [01:40<00:00,  3.87it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s]\n",
            "Test Epoch: [76/501] Acc@1:66.68% Acc@5:97.44%: 100%|██████████| 79/79 [00:06<00:00, 12.17it/s]\n",
            "Train Epoch: [77/501] Loss: 1.3421: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.27it/s]\n",
            "Test Epoch: [77/501] Acc@1:66.61% Acc@5:97.59%: 100%|██████████| 79/79 [00:06<00:00, 12.09it/s]\n",
            "Train Epoch: [78/501] Loss: 1.3661: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.49it/s]\n",
            "Test Epoch: [78/501] Acc@1:66.62% Acc@5:97.51%: 100%|██████████| 79/79 [00:06<00:00, 11.71it/s]\n",
            "Train Epoch: [79/501] Loss: 1.3362: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.91it/s]\n",
            "Test Epoch: [79/501] Acc@1:66.54% Acc@5:97.29%: 100%|██████████| 79/79 [00:06<00:00, 12.01it/s]\n",
            "Train Epoch: [80/501] Loss: 1.3415: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.90it/s]\n",
            "Test Epoch: [80/501] Acc@1:67.64% Acc@5:97.48%: 100%|██████████| 79/79 [00:06<00:00, 11.86it/s]\n",
            "Train Epoch: [81/501] Loss: 1.3467: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.12it/s]\n",
            "Test Epoch: [81/501] Acc@1:67.37% Acc@5:97.59%: 100%|██████████| 79/79 [00:06<00:00, 12.09it/s]\n",
            "Train Epoch: [82/501] Loss: 1.3411: 100%|██████████| 390/390 [01:41<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.04it/s]\n",
            "Test Epoch: [82/501] Acc@1:67.02% Acc@5:97.48%: 100%|██████████| 79/79 [00:06<00:00, 12.07it/s]\n",
            "Train Epoch: [83/501] Loss: 1.3428: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.00it/s]\n",
            "Test Epoch: [83/501] Acc@1:67.51% Acc@5:97.63%: 100%|██████████| 79/79 [00:06<00:00, 12.06it/s]\n",
            "Train Epoch: [84/501] Loss: 1.3335: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.98it/s]\n",
            "Test Epoch: [84/501] Acc@1:67.44% Acc@5:97.59%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [85/501] Loss: 1.3254: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.94it/s]\n",
            "Test Epoch: [85/501] Acc@1:67.41% Acc@5:97.60%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [86/501] Loss: 1.3229: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.90it/s]\n",
            "Test Epoch: [86/501] Acc@1:67.64% Acc@5:97.65%: 100%|██████████| 79/79 [00:06<00:00, 12.00it/s]\n",
            "Train Epoch: [87/501] Loss: 1.3377: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.78it/s]\n",
            "Test Epoch: [87/501] Acc@1:67.64% Acc@5:97.63%: 100%|██████████| 79/79 [00:06<00:00, 12.16it/s]\n",
            "Train Epoch: [88/501] Loss: 1.3103: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.13it/s]\n",
            "Test Epoch: [88/501] Acc@1:68.35% Acc@5:97.62%: 100%|██████████| 79/79 [00:07<00:00,  9.94it/s]\n",
            "Train Epoch: [89/501] Loss: 1.3164: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.91it/s]\n",
            "Test Epoch: [89/501] Acc@1:68.38% Acc@5:97.73%: 100%|██████████| 79/79 [00:06<00:00, 12.14it/s]\n",
            "Train Epoch: [90/501] Loss: 1.2957: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.42it/s]\n",
            "Test Epoch: [90/501] Acc@1:67.83% Acc@5:97.72%: 100%|██████████| 79/79 [00:06<00:00, 12.22it/s]\n",
            "Train Epoch: [91/501] Loss: 1.2977: 100%|██████████| 390/390 [01:41<00:00,  3.85it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.08it/s]\n",
            "Test Epoch: [91/501] Acc@1:67.88% Acc@5:97.63%: 100%|██████████| 79/79 [00:06<00:00, 12.14it/s]\n",
            "Train Epoch: [92/501] Loss: 1.3045: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.11it/s]\n",
            "Test Epoch: [92/501] Acc@1:68.12% Acc@5:97.63%: 100%|██████████| 79/79 [00:06<00:00, 12.06it/s]\n",
            "Train Epoch: [93/501] Loss: 1.2865: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.99it/s]\n",
            "Test Epoch: [93/501] Acc@1:67.85% Acc@5:97.63%: 100%|██████████| 79/79 [00:06<00:00, 11.92it/s]\n",
            "Train Epoch: [94/501] Loss: 1.2984: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.84it/s]\n",
            "Test Epoch: [94/501] Acc@1:67.85% Acc@5:97.70%: 100%|██████████| 79/79 [00:06<00:00, 12.33it/s]\n",
            "Train Epoch: [95/501] Loss: 1.2904: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.11it/s]\n",
            "Test Epoch: [95/501] Acc@1:67.62% Acc@5:97.61%: 100%|██████████| 79/79 [00:06<00:00, 11.95it/s]\n",
            "Train Epoch: [96/501] Loss: 1.2889: 100%|██████████| 390/390 [01:41<00:00,  3.84it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.26it/s]\n",
            "Test Epoch: [96/501] Acc@1:67.60% Acc@5:97.65%: 100%|██████████| 79/79 [00:06<00:00, 11.95it/s]\n",
            "Train Epoch: [97/501] Loss: 1.2984: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.91it/s]\n",
            "Test Epoch: [97/501] Acc@1:67.90% Acc@5:97.72%: 100%|██████████| 79/79 [00:06<00:00, 11.88it/s]\n",
            "Train Epoch: [98/501] Loss: 1.2777: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 19.06it/s]\n",
            "Test Epoch: [98/501] Acc@1:67.35% Acc@5:97.65%: 100%|██████████| 79/79 [00:06<00:00, 11.95it/s]\n",
            "Train Epoch: [99/501] Loss: 1.2764: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.89it/s]\n",
            "Test Epoch: [99/501] Acc@1:67.94% Acc@5:97.72%: 100%|██████████| 79/79 [00:06<00:00, 11.81it/s]\n",
            "Train Epoch: [100/501] Loss: 1.2749: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.03it/s]\n",
            "Test Epoch: [100/501] Acc@1:67.96% Acc@5:97.75%: 100%|██████████| 79/79 [00:06<00:00, 11.69it/s]\n",
            "Train Epoch: [101/501] Loss: 1.2726: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.38it/s]\n",
            "Test Epoch: [101/501] Acc@1:67.84% Acc@5:97.84%: 100%|██████████| 79/79 [00:06<00:00, 11.70it/s]\n",
            "Train Epoch: [102/501] Loss: 1.2783: 100%|██████████| 390/390 [01:45<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.66it/s]\n",
            "Test Epoch: [102/501] Acc@1:68.35% Acc@5:97.76%: 100%|██████████| 79/79 [00:06<00:00, 12.04it/s]\n",
            "Train Epoch: [103/501] Loss: 1.2726: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.29it/s]\n",
            "Test Epoch: [103/501] Acc@1:68.92% Acc@5:97.66%: 100%|██████████| 79/79 [00:06<00:00, 11.74it/s]\n",
            "Train Epoch: [104/501] Loss: 1.2758: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.20it/s]\n",
            "Test Epoch: [104/501] Acc@1:68.63% Acc@5:97.87%: 100%|██████████| 79/79 [00:06<00:00, 11.69it/s]\n",
            "Train Epoch: [105/501] Loss: 1.2643: 100%|██████████| 390/390 [01:45<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.39it/s]\n",
            "Test Epoch: [105/501] Acc@1:68.58% Acc@5:97.80%: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n",
            "Train Epoch: [106/501] Loss: 1.2540: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.54it/s]\n",
            "Test Epoch: [106/501] Acc@1:68.97% Acc@5:97.85%: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n",
            "Train Epoch: [107/501] Loss: 1.2535: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.70it/s]\n",
            "Test Epoch: [107/501] Acc@1:68.43% Acc@5:97.94%: 100%|██████████| 79/79 [00:06<00:00, 11.60it/s]\n",
            "Train Epoch: [108/501] Loss: 1.2554: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.17it/s]\n",
            "Test Epoch: [108/501] Acc@1:68.21% Acc@5:97.84%: 100%|██████████| 79/79 [00:06<00:00, 11.83it/s]\n",
            "Train Epoch: [109/501] Loss: 1.2525: 100%|██████████| 390/390 [01:46<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n",
            "Test Epoch: [109/501] Acc@1:68.56% Acc@5:97.87%: 100%|██████████| 79/79 [00:06<00:00, 11.35it/s]\n",
            "Train Epoch: [110/501] Loss: 1.2569: 100%|██████████| 390/390 [01:45<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.46it/s]\n",
            "Test Epoch: [110/501] Acc@1:68.85% Acc@5:97.69%: 100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n",
            "Train Epoch: [111/501] Loss: 1.2439: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.39it/s]\n",
            "Test Epoch: [111/501] Acc@1:68.58% Acc@5:97.81%: 100%|██████████| 79/79 [00:06<00:00, 11.93it/s]\n",
            "Train Epoch: [112/501] Loss: 1.2632: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.30it/s]\n",
            "Test Epoch: [112/501] Acc@1:68.88% Acc@5:97.91%: 100%|██████████| 79/79 [00:06<00:00, 11.75it/s]\n",
            "Train Epoch: [113/501] Loss: 1.2420: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.40it/s]\n",
            "Test Epoch: [113/501] Acc@1:69.05% Acc@5:97.83%: 100%|██████████| 79/79 [00:06<00:00, 11.60it/s]\n",
            "Train Epoch: [114/501] Loss: 1.2478: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.13it/s]\n",
            "Test Epoch: [114/501] Acc@1:69.00% Acc@5:97.79%: 100%|██████████| 79/79 [00:06<00:00, 11.78it/s]\n",
            "Train Epoch: [115/501] Loss: 1.2325: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.23it/s]\n",
            "Test Epoch: [115/501] Acc@1:69.54% Acc@5:97.93%: 100%|██████████| 79/79 [00:06<00:00, 11.98it/s]\n",
            "Train Epoch: [116/501] Loss: 1.2174: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.93it/s]\n",
            "Test Epoch: [116/501] Acc@1:69.30% Acc@5:97.73%: 100%|██████████| 79/79 [00:06<00:00, 11.58it/s]\n",
            "Train Epoch: [117/501] Loss: 1.2251: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.93it/s]\n",
            "Test Epoch: [117/501] Acc@1:68.77% Acc@5:97.72%: 100%|██████████| 79/79 [00:06<00:00, 11.51it/s]\n",
            "Train Epoch: [118/501] Loss: 1.2279: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.36it/s]\n",
            "Test Epoch: [118/501] Acc@1:68.26% Acc@5:97.92%: 100%|██████████| 79/79 [00:06<00:00, 11.63it/s]\n",
            "Train Epoch: [119/501] Loss: 1.2323: 100%|██████████| 390/390 [01:46<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.95it/s]\n",
            "Test Epoch: [119/501] Acc@1:69.88% Acc@5:97.86%: 100%|██████████| 79/79 [00:07<00:00, 11.27it/s]\n",
            "Train Epoch: [120/501] Loss: 1.2281: 100%|██████████| 390/390 [01:49<00:00,  3.56it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.65it/s]\n",
            "Test Epoch: [120/501] Acc@1:69.29% Acc@5:97.96%: 100%|██████████| 79/79 [00:07<00:00, 11.21it/s]\n",
            "Train Epoch: [121/501] Loss: 1.2227: 100%|██████████| 390/390 [01:46<00:00,  3.67it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.87it/s]\n",
            "Test Epoch: [121/501] Acc@1:69.33% Acc@5:97.91%: 100%|██████████| 79/79 [00:07<00:00, 11.23it/s]\n",
            "Train Epoch: [122/501] Loss: 1.2153: 100%|██████████| 390/390 [01:47<00:00,  3.63it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.90it/s]\n",
            "Test Epoch: [122/501] Acc@1:69.08% Acc@5:97.77%: 100%|██████████| 79/79 [00:07<00:00, 11.14it/s]\n",
            "Train Epoch: [123/501] Loss: 1.2058: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.37it/s]\n",
            "Test Epoch: [123/501] Acc@1:69.57% Acc@5:98.01%: 100%|██████████| 79/79 [00:06<00:00, 11.41it/s]\n",
            "Train Epoch: [124/501] Loss: 1.2178: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.43it/s]\n",
            "Test Epoch: [124/501] Acc@1:69.82% Acc@5:97.88%: 100%|██████████| 79/79 [00:06<00:00, 11.68it/s]\n",
            "Train Epoch: [125/501] Loss: 1.2168: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.49it/s]\n",
            "Test Epoch: [125/501] Acc@1:69.59% Acc@5:97.83%: 100%|██████████| 79/79 [00:06<00:00, 11.93it/s]\n",
            "Train Epoch: [126/501] Loss: 1.2082: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.62it/s]\n",
            "Test Epoch: [126/501] Acc@1:69.47% Acc@5:98.13%: 100%|██████████| 79/79 [00:06<00:00, 11.57it/s]\n",
            "Train Epoch: [127/501] Loss: 1.2194: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.18it/s]\n",
            "Test Epoch: [127/501] Acc@1:69.21% Acc@5:97.94%: 100%|██████████| 79/79 [00:06<00:00, 11.38it/s]\n",
            "Train Epoch: [128/501] Loss: 1.2063: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.64it/s]\n",
            "Test Epoch: [128/501] Acc@1:69.85% Acc@5:97.99%: 100%|██████████| 79/79 [00:06<00:00, 11.62it/s]\n",
            "Train Epoch: [129/501] Loss: 1.2034: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.80it/s]\n",
            "Test Epoch: [129/501] Acc@1:69.49% Acc@5:97.87%: 100%|██████████| 79/79 [00:07<00:00, 10.90it/s]\n",
            "Train Epoch: [130/501] Loss: 1.2095: 100%|██████████| 390/390 [01:42<00:00,  3.79it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.39it/s]\n",
            "Test Epoch: [130/501] Acc@1:69.82% Acc@5:97.89%: 100%|██████████| 79/79 [00:06<00:00, 11.29it/s]\n",
            "Train Epoch: [131/501] Loss: 1.1941: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.50it/s]\n",
            "Test Epoch: [131/501] Acc@1:69.47% Acc@5:97.97%: 100%|██████████| 79/79 [00:07<00:00, 11.28it/s]\n",
            "Train Epoch: [132/501] Loss: 1.1846: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n",
            "Test Epoch: [132/501] Acc@1:70.01% Acc@5:97.94%: 100%|██████████| 79/79 [00:06<00:00, 11.71it/s]\n",
            "Train Epoch: [133/501] Loss: 1.1854: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.62it/s]\n",
            "Test Epoch: [133/501] Acc@1:69.76% Acc@5:98.17%: 100%|██████████| 79/79 [00:06<00:00, 11.67it/s]\n",
            "Train Epoch: [134/501] Loss: 1.1901: 100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.65it/s]\n",
            "Test Epoch: [134/501] Acc@1:69.82% Acc@5:98.03%: 100%|██████████| 79/79 [00:06<00:00, 11.72it/s]\n",
            "Train Epoch: [135/501] Loss: 1.1917: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.82it/s]\n",
            "Test Epoch: [135/501] Acc@1:69.81% Acc@5:97.94%: 100%|██████████| 79/79 [00:06<00:00, 11.49it/s]\n",
            "Train Epoch: [136/501] Loss: 1.1840: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.45it/s]\n",
            "Test Epoch: [136/501] Acc@1:69.68% Acc@5:98.02%: 100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n",
            "Train Epoch: [137/501] Loss: 1.1838: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.41it/s]\n",
            "Test Epoch: [137/501] Acc@1:69.71% Acc@5:97.97%: 100%|██████████| 79/79 [00:06<00:00, 11.44it/s]\n",
            "Train Epoch: [138/501] Loss: 1.1836: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.57it/s]\n",
            "Test Epoch: [138/501] Acc@1:70.33% Acc@5:98.17%: 100%|██████████| 79/79 [00:06<00:00, 11.56it/s]\n",
            "Train Epoch: [139/501] Loss: 1.1790: 100%|██████████| 390/390 [01:43<00:00,  3.76it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.55it/s]\n",
            "Test Epoch: [139/501] Acc@1:69.86% Acc@5:98.02%: 100%|██████████| 79/79 [00:06<00:00, 11.34it/s]\n",
            "Train Epoch: [140/501] Loss: 1.1763: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.84it/s]\n",
            "Test Epoch: [140/501] Acc@1:70.24% Acc@5:97.99%: 100%|██████████| 79/79 [00:06<00:00, 11.42it/s]\n",
            "Train Epoch: [141/501] Loss: 1.1727: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.75it/s]\n",
            "Test Epoch: [141/501] Acc@1:69.82% Acc@5:98.24%: 100%|██████████| 79/79 [00:06<00:00, 11.33it/s]\n",
            "Train Epoch: [142/501] Loss: 1.1817: 100%|██████████| 390/390 [01:42<00:00,  3.82it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.86it/s]\n",
            "Test Epoch: [142/501] Acc@1:69.48% Acc@5:98.03%: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n",
            "Train Epoch: [143/501] Loss: 1.1768: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.47it/s]\n",
            "Test Epoch: [143/501] Acc@1:69.74% Acc@5:98.21%: 100%|██████████| 79/79 [00:06<00:00, 11.39it/s]\n",
            "Train Epoch: [144/501] Loss: 1.1717: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.75it/s]\n",
            "Test Epoch: [144/501] Acc@1:69.72% Acc@5:98.09%: 100%|██████████| 79/79 [00:06<00:00, 11.31it/s]\n",
            "Train Epoch: [145/501] Loss: 1.1747: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.72it/s]\n",
            "Test Epoch: [145/501] Acc@1:69.77% Acc@5:97.95%: 100%|██████████| 79/79 [00:06<00:00, 12.03it/s]\n",
            "Train Epoch: [146/501] Loss: 1.1570: 100%|██████████| 390/390 [01:43<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n",
            "Test Epoch: [146/501] Acc@1:70.05% Acc@5:98.17%: 100%|██████████| 79/79 [00:07<00:00, 11.27it/s]\n",
            "Train Epoch: [147/501] Loss: 1.1628: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:20<00:00, 18.76it/s]\n",
            "Test Epoch: [147/501] Acc@1:70.42% Acc@5:97.89%: 100%|██████████| 79/79 [00:07<00:00, 11.04it/s]\n",
            "Train Epoch: [148/501] Loss: 1.1644: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.34it/s]\n",
            "Test Epoch: [148/501] Acc@1:70.23% Acc@5:98.10%: 100%|██████████| 79/79 [00:06<00:00, 11.40it/s]\n",
            "Train Epoch: [149/501] Loss: 1.1659: 100%|██████████| 390/390 [01:42<00:00,  3.81it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.46it/s]\n",
            "Test Epoch: [149/501] Acc@1:71.07% Acc@5:98.29%: 100%|██████████| 79/79 [00:07<00:00, 11.24it/s]\n",
            "Train Epoch: [150/501] Loss: 1.1627: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.44it/s]\n",
            "Test Epoch: [150/501] Acc@1:70.45% Acc@5:98.16%: 100%|██████████| 79/79 [00:06<00:00, 11.30it/s]\n",
            "Train Epoch: [151/501] Loss: 1.1501: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.25it/s]\n",
            "Test Epoch: [151/501] Acc@1:70.69% Acc@5:98.26%: 100%|██████████| 79/79 [00:07<00:00, 11.28it/s]\n",
            "Train Epoch: [152/501] Loss: 1.1514: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.95it/s]\n",
            "Test Epoch: [152/501] Acc@1:70.35% Acc@5:98.26%: 100%|██████████| 79/79 [00:07<00:00, 11.19it/s]\n",
            "Train Epoch: [153/501] Loss: 1.1534: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.20it/s]\n",
            "Test Epoch: [153/501] Acc@1:71.11% Acc@5:98.28%: 100%|██████████| 79/79 [00:06<00:00, 11.30it/s]\n",
            "Train Epoch: [154/501] Loss: 1.1485: 100%|██████████| 390/390 [01:45<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.10it/s]\n",
            "Test Epoch: [154/501] Acc@1:71.11% Acc@5:98.16%: 100%|██████████| 79/79 [00:07<00:00, 10.91it/s]\n",
            "Train Epoch: [155/501] Loss: 1.1451: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.83it/s]\n",
            "Test Epoch: [155/501] Acc@1:70.96% Acc@5:98.06%: 100%|██████████| 79/79 [00:07<00:00, 11.18it/s]\n",
            "Train Epoch: [156/501] Loss: 1.1352: 100%|██████████| 390/390 [01:45<00:00,  3.71it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.68it/s]\n",
            "Test Epoch: [156/501] Acc@1:70.96% Acc@5:98.09%: 100%|██████████| 79/79 [00:07<00:00, 10.95it/s]\n",
            "Train Epoch: [157/501] Loss: 1.1529: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.92it/s]\n",
            "Test Epoch: [157/501] Acc@1:70.63% Acc@5:98.14%: 100%|██████████| 79/79 [00:07<00:00, 10.99it/s]\n",
            "Train Epoch: [158/501] Loss: 1.1385: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.97it/s]\n",
            "Test Epoch: [158/501] Acc@1:70.95% Acc@5:98.14%: 100%|██████████| 79/79 [00:07<00:00, 11.10it/s]\n",
            "Train Epoch: [159/501] Loss: 1.1396: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.36it/s]\n",
            "Test Epoch: [159/501] Acc@1:71.22% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.89it/s]\n",
            "Train Epoch: [160/501] Loss: 1.1356: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.04it/s]\n",
            "Test Epoch: [160/501] Acc@1:70.89% Acc@5:98.32%: 100%|██████████| 79/79 [00:07<00:00, 11.02it/s]\n",
            "Train Epoch: [161/501] Loss: 1.1318: 100%|██████████| 390/390 [01:42<00:00,  3.80it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.46it/s]\n",
            "Test Epoch: [161/501] Acc@1:70.86% Acc@5:98.10%: 100%|██████████| 79/79 [00:07<00:00, 11.19it/s]\n",
            "Train Epoch: [162/501] Loss: 1.1361: 100%|██████████| 390/390 [01:43<00:00,  3.78it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.56it/s]\n",
            "Test Epoch: [162/501] Acc@1:70.97% Acc@5:98.20%: 100%|██████████| 79/79 [00:06<00:00, 11.32it/s]\n",
            "Train Epoch: [163/501] Loss: 1.1293: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.32it/s]\n",
            "Test Epoch: [163/501] Acc@1:71.49% Acc@5:98.17%: 100%|██████████| 79/79 [00:06<00:00, 11.37it/s]\n",
            "Train Epoch: [164/501] Loss: 1.1277: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.34it/s]\n",
            "Test Epoch: [164/501] Acc@1:70.97% Acc@5:98.17%: 100%|██████████| 79/79 [00:07<00:00, 11.18it/s]\n",
            "Train Epoch: [165/501] Loss: 1.1317: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.23it/s]\n",
            "Test Epoch: [165/501] Acc@1:70.98% Acc@5:98.34%: 100%|██████████| 79/79 [00:07<00:00, 11.10it/s]\n",
            "Train Epoch: [166/501] Loss: 1.1303: 100%|██████████| 390/390 [01:43<00:00,  3.77it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.35it/s]\n",
            "Test Epoch: [166/501] Acc@1:71.68% Acc@5:98.28%: 100%|██████████| 79/79 [00:06<00:00, 11.30it/s]\n",
            "Train Epoch: [167/501] Loss: 1.1187: 100%|██████████| 390/390 [01:45<00:00,  3.71it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.78it/s]\n",
            "Test Epoch: [167/501] Acc@1:71.20% Acc@5:98.19%: 100%|██████████| 79/79 [00:07<00:00, 10.87it/s]\n",
            "Train Epoch: [168/501] Loss: 1.1217: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.55it/s]\n",
            "Test Epoch: [168/501] Acc@1:71.29% Acc@5:98.43%: 100%|██████████| 79/79 [00:07<00:00, 10.93it/s]\n",
            "Train Epoch: [169/501] Loss: 1.1091: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.71it/s]\n",
            "Test Epoch: [169/501] Acc@1:71.88% Acc@5:98.23%: 100%|██████████| 79/79 [00:07<00:00, 10.63it/s]\n",
            "Train Epoch: [170/501] Loss: 1.1332: 100%|██████████| 390/390 [01:47<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.55it/s]\n",
            "Test Epoch: [170/501] Acc@1:71.75% Acc@5:98.28%: 100%|██████████| 79/79 [00:07<00:00, 10.90it/s]\n",
            "Train Epoch: [171/501] Loss: 1.1143: 100%|██████████| 390/390 [01:47<00:00,  3.63it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.41it/s]\n",
            "Test Epoch: [171/501] Acc@1:72.19% Acc@5:98.17%: 100%|██████████| 79/79 [00:07<00:00, 10.52it/s]\n",
            "Train Epoch: [172/501] Loss: 1.1109: 100%|██████████| 390/390 [01:51<00:00,  3.50it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.68it/s]\n",
            "Test Epoch: [172/501] Acc@1:71.79% Acc@5:98.26%: 100%|██████████| 79/79 [00:07<00:00, 10.84it/s]\n",
            "Train Epoch: [173/501] Loss: 1.1042: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.71it/s]\n",
            "Test Epoch: [173/501] Acc@1:71.98% Acc@5:98.34%: 100%|██████████| 79/79 [00:07<00:00, 10.82it/s]\n",
            "Train Epoch: [174/501] Loss: 1.1071: 100%|██████████| 390/390 [01:46<00:00,  3.66it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.17it/s]\n",
            "Test Epoch: [174/501] Acc@1:71.74% Acc@5:98.29%: 100%|██████████| 79/79 [00:07<00:00, 10.70it/s]\n",
            "Train Epoch: [175/501] Loss: 1.1142: 100%|██████████| 390/390 [01:48<00:00,  3.59it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.64it/s]\n",
            "Test Epoch: [175/501] Acc@1:72.09% Acc@5:98.38%: 100%|██████████| 79/79 [00:07<00:00, 10.95it/s]\n",
            "Train Epoch: [176/501] Loss: 1.0913: 100%|██████████| 390/390 [01:48<00:00,  3.59it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.52it/s]\n",
            "Test Epoch: [176/501] Acc@1:72.34% Acc@5:98.41%: 100%|██████████| 79/79 [00:07<00:00, 10.77it/s]\n",
            "Train Epoch: [177/501] Loss: 1.1039: 100%|██████████| 390/390 [01:48<00:00,  3.58it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.38it/s]\n",
            "Test Epoch: [177/501] Acc@1:71.90% Acc@5:98.33%: 100%|██████████| 79/79 [00:07<00:00, 10.62it/s]\n",
            "Train Epoch: [178/501] Loss: 1.1115: 100%|██████████| 390/390 [01:47<00:00,  3.63it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.62it/s]\n",
            "Test Epoch: [178/501] Acc@1:72.10% Acc@5:98.23%: 100%|██████████| 79/79 [00:07<00:00, 10.37it/s]\n",
            "Train Epoch: [179/501] Loss: 1.0934: 100%|██████████| 390/390 [01:46<00:00,  3.65it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.88it/s]\n",
            "Test Epoch: [179/501] Acc@1:71.92% Acc@5:98.27%: 100%|██████████| 79/79 [00:07<00:00, 10.74it/s]\n",
            "Train Epoch: [180/501] Loss: 1.0972: 100%|██████████| 390/390 [01:46<00:00,  3.67it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.67it/s]\n",
            "Test Epoch: [180/501] Acc@1:72.12% Acc@5:98.29%: 100%|██████████| 79/79 [00:07<00:00, 10.81it/s]\n",
            "Train Epoch: [181/501] Loss: 1.0832: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.89it/s]\n",
            "Test Epoch: [181/501] Acc@1:72.60% Acc@5:98.42%: 100%|██████████| 79/79 [00:07<00:00, 10.60it/s]\n",
            "Train Epoch: [182/501] Loss: 1.0899: 100%|██████████| 390/390 [01:49<00:00,  3.57it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.83it/s]\n",
            "Test Epoch: [182/501] Acc@1:71.95% Acc@5:98.31%: 100%|██████████| 79/79 [00:07<00:00, 10.68it/s]\n",
            "Train Epoch: [183/501] Loss: 1.0939: 100%|██████████| 390/390 [01:45<00:00,  3.68it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.67it/s]\n",
            "Test Epoch: [183/501] Acc@1:72.10% Acc@5:98.45%: 100%|██████████| 79/79 [00:07<00:00, 10.79it/s]\n",
            "Train Epoch: [184/501] Loss: 1.0960: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.45it/s]\n",
            "Test Epoch: [184/501] Acc@1:71.93% Acc@5:98.23%: 100%|██████████| 79/79 [00:07<00:00, 10.53it/s]\n",
            "Train Epoch: [185/501] Loss: 1.0771: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.41it/s]\n",
            "Test Epoch: [185/501] Acc@1:72.38% Acc@5:98.28%: 100%|██████████| 79/79 [00:07<00:00, 10.68it/s]\n",
            "Train Epoch: [186/501] Loss: 1.0868: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.02it/s]\n",
            "Test Epoch: [186/501] Acc@1:72.32% Acc@5:98.16%: 100%|██████████| 79/79 [00:07<00:00, 10.50it/s]\n",
            "Train Epoch: [187/501] Loss: 1.0814: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.60it/s]\n",
            "Test Epoch: [187/501] Acc@1:72.60% Acc@5:98.50%: 100%|██████████| 79/79 [00:07<00:00, 10.57it/s]\n",
            "Train Epoch: [188/501] Loss: 1.0817: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:23<00:00, 16.77it/s]\n",
            "Test Epoch: [188/501] Acc@1:72.79% Acc@5:98.38%: 100%|██████████| 79/79 [00:07<00:00, 10.67it/s]\n",
            "Train Epoch: [189/501] Loss: 1.0842: 100%|██████████| 390/390 [01:46<00:00,  3.65it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.88it/s]\n",
            "Test Epoch: [189/501] Acc@1:72.37% Acc@5:98.39%: 100%|██████████| 79/79 [00:07<00:00, 10.95it/s]\n",
            "Train Epoch: [190/501] Loss: 1.0657: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.80it/s]\n",
            "Test Epoch: [190/501] Acc@1:72.66% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.88it/s]\n",
            "Train Epoch: [191/501] Loss: 1.0761: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.77it/s]\n",
            "Test Epoch: [191/501] Acc@1:72.39% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.84it/s]\n",
            "Train Epoch: [192/501] Loss: 1.0752: 100%|██████████| 390/390 [01:45<00:00,  3.70it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.77it/s]\n",
            "Test Epoch: [192/501] Acc@1:72.28% Acc@5:98.29%: 100%|██████████| 79/79 [00:07<00:00, 10.27it/s]\n",
            "Train Epoch: [193/501] Loss: 1.0702: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.98it/s]\n",
            "Test Epoch: [193/501] Acc@1:72.51% Acc@5:98.32%: 100%|██████████| 79/79 [00:07<00:00, 10.69it/s]\n",
            "Train Epoch: [194/501] Loss: 1.0708: 100%|██████████| 390/390 [01:46<00:00,  3.67it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.30it/s]\n",
            "Test Epoch: [194/501] Acc@1:72.86% Acc@5:98.27%: 100%|██████████| 79/79 [00:07<00:00, 10.65it/s]\n",
            "Train Epoch: [195/501] Loss: 1.0727: 100%|██████████| 390/390 [01:49<00:00,  3.57it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.27it/s]\n",
            "Test Epoch: [195/501] Acc@1:73.00% Acc@5:98.32%: 100%|██████████| 79/79 [00:07<00:00, 10.44it/s]\n",
            "Train Epoch: [196/501] Loss: 1.0733: 100%|██████████| 390/390 [01:49<00:00,  3.57it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.46it/s]\n",
            "Test Epoch: [196/501] Acc@1:72.58% Acc@5:98.36%: 100%|██████████| 79/79 [00:07<00:00, 10.77it/s]\n",
            "Train Epoch: [197/501] Loss: 1.0464: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.33it/s]\n",
            "Test Epoch: [197/501] Acc@1:72.67% Acc@5:98.21%: 100%|██████████| 79/79 [00:07<00:00, 10.39it/s]\n",
            "Train Epoch: [198/501] Loss: 1.0484: 100%|██████████| 390/390 [01:48<00:00,  3.59it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.15it/s]\n",
            "Test Epoch: [198/501] Acc@1:73.10% Acc@5:98.29%: 100%|██████████| 79/79 [00:07<00:00, 10.40it/s]\n",
            "Train Epoch: [199/501] Loss: 1.0562: 100%|██████████| 390/390 [01:50<00:00,  3.53it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:23<00:00, 16.81it/s]\n",
            "Test Epoch: [199/501] Acc@1:72.90% Acc@5:98.58%: 100%|██████████| 79/79 [00:07<00:00, 10.35it/s]\n",
            "Train Epoch: [200/501] Loss: 1.0619: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.19it/s]\n",
            "Test Epoch: [200/501] Acc@1:72.95% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.35it/s]\n",
            "Train Epoch: [201/501] Loss: 1.0531: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.33it/s]\n",
            "Test Epoch: [201/501] Acc@1:72.94% Acc@5:98.49%: 100%|██████████| 79/79 [00:07<00:00, 10.46it/s]\n",
            "Train Epoch: [202/501] Loss: 1.0512: 100%|██████████| 390/390 [01:48<00:00,  3.60it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.69it/s]\n",
            "Test Epoch: [202/501] Acc@1:73.20% Acc@5:98.33%: 100%|██████████| 79/79 [00:07<00:00, 10.43it/s]\n",
            "Train Epoch: [203/501] Loss: 1.0482: 100%|██████████| 390/390 [01:47<00:00,  3.62it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.21it/s]\n",
            "Test Epoch: [203/501] Acc@1:73.37% Acc@5:98.39%: 100%|██████████| 79/79 [00:07<00:00, 10.89it/s]\n",
            "Train Epoch: [204/501] Loss: 1.0482: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.21it/s]\n",
            "Test Epoch: [204/501] Acc@1:73.07% Acc@5:98.54%: 100%|██████████| 79/79 [00:07<00:00, 10.80it/s]\n",
            "Train Epoch: [205/501] Loss: 1.0345: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.28it/s]\n",
            "Test Epoch: [205/501] Acc@1:72.88% Acc@5:98.44%: 100%|██████████| 79/79 [00:07<00:00, 10.75it/s]\n",
            "Train Epoch: [206/501] Loss: 1.0432: 100%|██████████| 390/390 [01:45<00:00,  3.69it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.87it/s]\n",
            "Test Epoch: [206/501] Acc@1:73.11% Acc@5:98.46%: 100%|██████████| 79/79 [00:07<00:00, 10.56it/s]\n",
            "Train Epoch: [207/501] Loss: 1.0456: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.10it/s]\n",
            "Test Epoch: [207/501] Acc@1:73.09% Acc@5:98.45%: 100%|██████████| 79/79 [00:07<00:00, 10.81it/s]\n",
            "Train Epoch: [208/501] Loss: 1.0337: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.17it/s]\n",
            "Test Epoch: [208/501] Acc@1:73.07% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.64it/s]\n",
            "Train Epoch: [209/501] Loss: 1.0467: 100%|██████████| 390/390 [01:44<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.73it/s]\n",
            "Test Epoch: [209/501] Acc@1:73.46% Acc@5:98.48%: 100%|██████████| 79/79 [00:07<00:00, 10.40it/s]\n",
            "Train Epoch: [210/501] Loss: 1.0377: 100%|██████████| 390/390 [01:46<00:00,  3.65it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.78it/s]\n",
            "Test Epoch: [210/501] Acc@1:73.34% Acc@5:98.50%: 100%|██████████| 79/79 [00:07<00:00, 10.51it/s]\n",
            "Train Epoch: [211/501] Loss: 1.0425: 100%|██████████| 390/390 [01:44<00:00,  3.73it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.04it/s]\n",
            "Test Epoch: [211/501] Acc@1:73.01% Acc@5:98.49%: 100%|██████████| 79/79 [00:07<00:00, 10.79it/s]\n",
            "Train Epoch: [212/501] Loss: 1.0337: 100%|██████████| 390/390 [01:44<00:00,  3.72it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.93it/s]\n",
            "Test Epoch: [212/501] Acc@1:73.15% Acc@5:98.48%: 100%|██████████| 79/79 [00:07<00:00, 10.79it/s]\n",
            "Train Epoch: [213/501] Loss: 1.0283: 100%|██████████| 390/390 [01:48<00:00,  3.61it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.00it/s]\n",
            "Test Epoch: [213/501] Acc@1:73.32% Acc@5:98.39%: 100%|██████████| 79/79 [00:07<00:00, 10.60it/s]\n",
            "Train Epoch: [214/501] Loss: 1.0312: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.88it/s]\n",
            "Test Epoch: [214/501] Acc@1:73.54% Acc@5:98.55%: 100%|██████████| 79/79 [00:07<00:00, 10.96it/s]\n",
            "Train Epoch: [215/501] Loss: 1.0329: 100%|██████████| 390/390 [01:45<00:00,  3.71it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.84it/s]\n",
            "Test Epoch: [215/501] Acc@1:73.22% Acc@5:98.46%: 100%|██████████| 79/79 [00:07<00:00, 10.96it/s]\n",
            "Train Epoch: [216/501] Loss: 1.0248: 100%|██████████| 390/390 [01:43<00:00,  3.75it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.11it/s]\n",
            "Test Epoch: [216/501] Acc@1:73.20% Acc@5:98.42%: 100%|██████████| 79/79 [00:07<00:00, 10.61it/s]\n",
            "Train Epoch: [217/501] Loss: 1.0257: 100%|██████████| 390/390 [01:44<00:00,  3.74it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 17.90it/s]\n",
            "Test Epoch: [217/501] Acc@1:73.88% Acc@5:98.51%: 100%|██████████| 79/79 [00:07<00:00, 10.66it/s]\n",
            "Train Epoch: [218/501] Loss: 1.0250: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:21<00:00, 18.40it/s]\n",
            "Test Epoch: [218/501] Acc@1:73.14% Acc@5:98.40%: 100%|██████████| 79/79 [00:07<00:00, 10.73it/s]\n",
            "Train Epoch: [219/501] Loss: 1.0174: 100%|██████████| 390/390 [01:47<00:00,  3.63it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.34it/s]\n",
            "Test Epoch: [219/501] Acc@1:73.23% Acc@5:98.44%: 100%|██████████| 79/79 [00:07<00:00, 10.07it/s]\n",
            "Train Epoch: [220/501] Loss: 1.0198: 100%|██████████| 390/390 [01:47<00:00,  3.64it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:22<00:00, 17.46it/s]\n",
            "Test Epoch: [220/501] Acc@1:73.79% Acc@5:98.56%: 100%|██████████| 79/79 [00:07<00:00, 10.63it/s]\n",
            "Train Epoch: [221/501] Loss: 1.0183: 100%|██████████| 390/390 [01:46<00:00,  3.65it/s]\n",
            "Feature extracting: 100%|██████████| 391/391 [00:23<00:00, 16.99it/s]\n",
            "Test Epoch: [221/501] Acc@1:73.79% Acc@5:98.45%:  82%|████████▏ | 65/79 [00:06<00:00, 29.82it/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "!pip install thop\n",
        "from thop import profile, clever_format\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gdrive.MyDrive.CS5260Project.pytorch_lamb_master.optim.lamb import create_lamb_optimizer\n",
        "from gdrive.MyDrive.CS5260Project.pytorch_lamb_master.optim import lr_scheduler\n",
        "import math\n",
        "\n",
        "#!pip install torchlars\n",
        "#from torchlars import LARS\n",
        "\n",
        "import pickle\n",
        "\n",
        "def contrastive_loss(out_1, out_2, temperature):\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # START OF YOUR CODE\n",
        "    # ------------------------------------------------------------------\n",
        "    # Task2: implement contrastive loss function and return loss variable\n",
        "    # hint: loss formula could refer to the slides\n",
        "    # input: out_1, out_2，temperature\n",
        "    # output: loss variable\n",
        "\n",
        "    out = torch.cat([out_1, out_2], dim=0)\n",
        "    # [2*B, 2*B]\n",
        "    sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
        "    mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n",
        "    # [2*B, 2*B-1]\n",
        "    sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
        "\n",
        "    # compute loss\n",
        "    pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
        "    # [2*B]\n",
        "    pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
        "    loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean() \n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # END OF YOUR CODE\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    return loss\n",
        "\n",
        "# train for one epoch to learn unique features\n",
        "def train(net, data_loader, train_optimizer, train_scheduler, temperature):\n",
        "    net.train()\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
        "    for pos_1, pos_2, target in train_bar:\n",
        "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
        "        feature_1, out_1 = net(pos_1)\n",
        "        feature_2, out_2 = net(pos_2)\n",
        "\n",
        "        loss = contrastive_loss(out_1, out_2, temperature)\n",
        "\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "        train_scheduler.step()\n",
        "\n",
        "        total_num += batch_size\n",
        "        total_loss += loss.item() * batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "\n",
        "# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n",
        "def test(net, memory_data_loader, test_data_loader, temperature):\n",
        "    net.eval()\n",
        "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
        "    with torch.no_grad():\n",
        "        # generate feature bank\n",
        "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
        "            feature, out = net(data.cuda(non_blocking=True))\n",
        "            feature_bank.append(feature)\n",
        "        # [D, N]\n",
        "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
        "        # [N]\n",
        "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
        "        # loop test data to predict the label by weighted knn search\n",
        "        test_bar = tqdm(test_data_loader)\n",
        "        for data, _, target in test_bar:\n",
        "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
        "            feature, out = net(data)\n",
        "\n",
        "            total_num += data.size(0)\n",
        "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
        "            sim_matrix = torch.mm(feature, feature_bank)\n",
        "            # [B, K]\n",
        "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
        "            # [B, K]\n",
        "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
        "            sim_weight = (sim_weight / temperature).exp()\n",
        "\n",
        "            # counts for each class\n",
        "            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n",
        "            # [B*K, C]\n",
        "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
        "            # weighted score ---> [B, C]\n",
        "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
        "\n",
        "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
        "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
        "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
        "\n",
        "    return total_top1 / total_num * 100, total_top5 / total_num * 100\n",
        "\n",
        "# Train SimCLR\n",
        "   \n",
        "# Feature dim for latent vector, Temperature used in softmax, Top k most similar images used to predict the label\n",
        "feature_dim, temp, k = 128, [0.1, 0.5, 1], 200\n",
        "# Number of images in each mini-batch, Number of sweeps over the dataset to train\n",
        "batch_size, epochs = 128, 501\n",
        "#batch_size, epochs = 64, 501\n",
        "# data prepare\n",
        "#train\n",
        "train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
        "#val\n",
        "memory_data = CIFAR10Pair(root='data', train=True, transform=test_transform, download=True)\n",
        "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "#test\n",
        "test_data = CIFAR10Pair(root='data', train=False, transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "\n",
        "IterationStr='2'\n",
        "os.chdir('/')\n",
        "pathtosave1=os.path.join('content','gdrive','MyDrive','CS5260Project','results','Simclr_ViT_Patchsize8_LAMB','Iteration'+IterationStr)\n",
        "if os.path.exists(pathtosave1)==False:\n",
        "  os.mkdir(pathtosave1)\n",
        "\n",
        "best_acc = 0.0\n",
        "  \n",
        "\n",
        "# training loop\n",
        "\n",
        "\n",
        "# model setup and optimizer config\n",
        "#model = Model(feature_dim).cuda()\n",
        "model = ViT().cuda()\n",
        "\n",
        "#SOURAV COMMENTED OUT \n",
        "#flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
        "#flops, params = clever_format([flops, params])\n",
        "#print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "#base_optimizer=optim.Adam(model.parameters(),lr=1e-3/torch.pow(torch.tensor(2.0),0.5*((batch_size/128)-1)), weight_decay=1e-6)\n",
        "#optimizer=LARS(optimizer=base_optimizer, eps=1e-8, trust_coef=0.001)\n",
        "\n",
        "optimizer=create_lamb_optimizer(model,lr=4/math.pow(2.0,4.0)/100.0, weight_decay=1.5,bias_correction=None)\n",
        "warmup_steps_set=math.floor(2.5/math.pow(2.0,4.0)*len(train_loader))\n",
        "scheduler=lr_scheduler.PolynomialWarmup(optimizer, decay_steps= epochs*len(train_loader),warmup_steps=warmup_steps_set,end_lr=0.0,power=1.0,last_epoch=-1)\n",
        "\n",
        "\n",
        "\n",
        "c = len(memory_data.classes)\n",
        "\n",
        "results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n",
        "best_acc = 0.0\n",
        "\n",
        "train_loss_epoch=torch.zeros(epochs)\n",
        "test_acc_1_epoch=torch.zeros(epochs)\n",
        "test_acc_5_epoch=torch.zeros(epochs)\n",
        "\n",
        "temp0=temp[0] #Temperature constant for contrastive loss\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, train_loader, optimizer, scheduler, temp0)\n",
        "    train_loss_epoch[epoch-1]=train_loss\n",
        "        \n",
        "    results['train_loss'].append(train_loss)\n",
        "    test_acc_1, test_acc_5 = test(model, memory_loader, test_loader, temp0)\n",
        "    results['test_acc@1'].append(test_acc_1)\n",
        "    results['test_acc@5'].append(test_acc_5)\n",
        "    # save statistics\n",
        "    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
        "\n",
        "    part1fname='{}_{}_{}_{}_{}'.format(feature_dim, temp0, k, batch_size, epochs)\n",
        "    part2csvfname='{}_statistics.csv'.format(part1fname)\n",
        "    save_name_csv = os.path.join(pathtosave1,part2csvfname)\n",
        "    \n",
        "    data_frame.to_csv(save_name_csv)\n",
        "    if test_acc_1 > best_acc:\n",
        "       best_acc = test_acc_1\n",
        "       part2mdlfname='{}_model.pth'.format(part1fname)\n",
        "       save_name_mdl=os.path.join(pathtosave1,part2mdlfname)\n",
        "       torch.save(model.state_dict(), save_name_mdl)\n",
        "    test_acc_1_epoch[epoch-1]=test_acc_1\n",
        "    test_acc_5_epoch[epoch-1]=test_acc_5#\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc2fmSbpO0Po"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(test_acc_1_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_w-5Fc7USjk"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp0"
      ],
      "metadata": {
        "id": "qmu-91hfGUxf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "simclr_ViT_500.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}