{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HptO0CSwNjie"
   },
   "source": [
    "# Contrastive Learning using Resnet50 Backbone, AID Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkIokoYtNI_G"
   },
   "source": [
    "Please submit this file to Luminus by **23:59 on 20 Mar**. \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. Finish 2 tasks according to the instructions. Only change the code in the required area and DO NOT change others or add new code/text snippets.\n",
    "2. Rename this file as \"Student_number.ipynb\". e.g., 'A0000000J.ipynb'. \n",
    "\n",
    "3. Submit the file to /Files/assignments/submission/assignment5. \n",
    "\n",
    "Please follow the instructions strictly, otherwise you might be penalized.\n",
    "\n",
    "If you has any questions, please propose it on Slack, or contact Ziheng Qin (e0823059@u.nus.edu) and Yong Liu (e0672130@u.nus.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXC8nEmxOMN6"
   },
   "source": [
    "First, we import the dataset and define transformation operations on it. We apply random transformation on images (crop + flip + colorjitter + grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbuX_FfqsjW6"
   },
   "source": [
    "#Data Loading Code fragments and Data for AID courtesy of vladan-stojnic, CMC-RSSR\n",
    "@InProceedings{Stojnic_2021_CVPR_Workshops,\n",
    "    author = {Stojnic, Vladan and Risojevic, Vladimir},\n",
    "    title = {Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding},\n",
    "    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n",
    "    month = {June},\n",
    "    year = {2021}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z0FjknlsZwl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c61bUj3dVpYD"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.utils.data as datautils\n",
    "import lmdb\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning \n",
    "    with open(path,'rb') as f:\n",
    "      img=Image.open(f)\n",
    "      return img.convert('RGB')\n",
    "\n",
    "class ClassificationImageDatasetPair(datautils.Dataset):\n",
    "    def __init__(self, root_path, images_to_use, transform=None, target_transform=None, multilabel_targets=None):\n",
    "        super(ClassificationImageDatasetPair, self).__init__()\n",
    "        \n",
    "        with open(images_to_use, 'r') as f:\n",
    "            self.samples = f.readlines()\n",
    "            \n",
    "        self.samples.sort()\n",
    "            \n",
    "        self.samples = [os.path.join(root_path, image_path.strip()) for image_path in self.samples]\n",
    "            \n",
    "        self.loader = pil_loader\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        if multilabel_targets:\n",
    "            self.targets = self._make_targets(multilabel_targets=multilabel_targets)\n",
    "        else:\n",
    "            classes, class_to_idx = self._find_classes(root_path)\n",
    "            self.targets = self._make_targets(class_to_idx=class_to_idx)\n",
    "            self.classes=classes\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, target = self.samples[index], self.targets[index]\n",
    "\n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            pos_1 = self.transform(img)\n",
    "            pos_2 = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        #print(f'pos_1 size {pos_1.size()}')\n",
    "        #print(f'pos_2_size {pos_2.size()}')\n",
    "        #print(target)\n",
    "\n",
    "        return pos_1, pos_2, target \n",
    "            \n",
    "    def _find_classes(self, dir):\n",
    "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "        \n",
    "    def _make_targets(self, class_to_idx=None, multilabel_targets=None):\n",
    "        if class_to_idx:\n",
    "            self.num_classes = len(class_to_idx)\n",
    "            return np.array([class_to_idx[os.path.split(os.path.split(sample)[0])[1]] for sample in self.samples])\n",
    "            \n",
    "        if multilabel_targets:\n",
    "            self.num_classes = len(multilabel_targets[os.path.split(self.samples[0])[1]])\n",
    "            return [multilabel_targets[os.path.split(sample)[1]] for sample in self.samples]\n",
    "            \n",
    "        raise ValueError(\"Either class_to_idx or multilabel_targets must be supplied!!!\")\n",
    "\n",
    "#cropsize=84\n",
    "#cropsize=48\n",
    "cropsize=56\n",
    "#cropsize=32\n",
    "#cropsize=64\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(cropsize),\n",
    "    transforms.RandomResizedCrop(cropsize),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[(0+100)/2,(-86.183+98.233)/2,(-107.857+94.478)/2],\n",
    "                         std=[(100-0)/2,(86.183+98.233)/2,(107.857+94.478)/2])]) \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(cropsize),\n",
    "    transforms.CenterCrop(cropsize),                                 \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[(0+100)/2,(-86.183+98.233)/2,(-107.857+94.478)/2],\n",
    "                         std=[(100-0)/2,(86.183+98.233)/2,(107.857+94.478)/2])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct01fnfSNHuT"
   },
   "source": [
    "We use commonly used ResNet-50 as ConvNet encoders for simplicity in the original paper. The task 1 is to set encoder and projection head. The parameters are adapted from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZbjYxzrgG6rO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.f = []\n",
    "        for name, module in resnet50().named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
    "                self.f.append(module)\n",
    "        # ----------------------------------------------------------------------\n",
    "        # START OF YOUR CODE\n",
    "        # ----------------------------------------------------------------------\n",
    "        # Task 1\n",
    "        # set a neural network base encoder self.f\n",
    "        # hint: nn.Sequential\n",
    "        # Reference : https://github.com/leftthomas/SimCLR/blob/master/model.py\n",
    "        self.f = nn.Sequential(*self.f)\n",
    "\n",
    "\n",
    "        # set a small neural network projection head\n",
    "        # Dense-> Relu-> Dense (2-layer MLP to project the representation to a 128-dimensional latent space and \n",
    "        # the representation is 2048-dimensional here)\n",
    "        # Reference : https://github.com/leftthomas/SimCLR/blob/master/model.py\n",
    "        self.g = nn.Sequential(nn.Linear(2048, 512, bias=False), nn.BatchNorm1d(512),\n",
    "                               nn.ReLU(inplace=True), nn.Linear(512, feature_dim, bias=True))\n",
    "     \n",
    "\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # END OF YOUR CODE\n",
    "        # ----------------------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        feature = torch.flatten(x, start_dim=1)\n",
    "        out = self.g(feature)\n",
    "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPM5hsulQ74i"
   },
   "source": [
    "We train encoder network and projection head to maximize agreement using a contrastive loss. The default epoch is 1 for time efficiency while it could takes about 10 minutes to run for one epoch in google colab. The task 2 is to calculate the contrastive loss.\n",
    "To evaluate the influence of temperature value for contrastive loss, we run this training process 3 times with different temperature value (0.1,0.5 and 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBTtTnQY-SHC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1188967,
     "status": "error",
     "timestamp": 1649281872268,
     "user": {
      "displayName": "Umaiyal Ramanathan",
      "userId": "12104065804675727870"
     },
     "user_tz": -480
    },
    "id": "w7FrLDw2HAWN",
    "outputId": "89badd36-94ca-4b75-e12f-6aa0b7541647",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thop in /home/umaiyal/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages (0.0.31.post2005241907)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/umaiyal/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages (from thop) (1.10.1+cu111)\r\n",
      "Requirement already satisfied: typing-extensions in /home/umaiyal/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages (from torch>=1.0.0->thop) (4.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "!pip install thop\n",
    "from thop import profile, clever_format\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from gdrive.MyDrive.CS5260Project.CMC_RSSR_main import dataset\n",
    "\n",
    "\n",
    "from pytorch_lamb_master.optim.lamb import create_lamb_optimizer\n",
    "from pytorch_lamb_master.optim import lr_scheduler\n",
    "import math\n",
    "\n",
    "def contrastive_loss(out_1, out_2, temperature):\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # START OF YOUR CODE\n",
    "    # ------------------------------------------------------------------\n",
    "    # Task2: implement contrastive loss function and return loss variable\n",
    "    # hint: loss formula could refer to the slides\n",
    "    # input: out_1, out_2，temperature\n",
    "    # output: loss variable\n",
    "\n",
    "    #print(out_1.size())\n",
    "    #print(out_2.size())\n",
    "\n",
    "    batch_size=out_1.size(dim=0) \n",
    "\n",
    "    out = torch.cat([out_1, out_2],dim=0)\n",
    "    # [2*B, 2*B]\n",
    "    sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
    "    mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n",
    "\n",
    "    # [2*B, 2*B-1]\n",
    "    sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
    "\n",
    "    # compute loss\n",
    "    pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "    # [2*B]\n",
    "    pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
    "    loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean() \n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # END OF YOUR CODE\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    return loss\n",
    "\n",
    "# train for one epoch to learn unique features\n",
    "def train(net, data_loader, train_optimizer, train_scheduler, temperature):\n",
    "    net.train()\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for pos_1, pos_2, target in train_bar:\n",
    "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
    "        feature_1, out_1 = net(pos_1)\n",
    "        feature_2, out_2 = net(pos_2)\n",
    "\n",
    "        loss = contrastive_loss(out_1, out_2, temperature)\n",
    "\n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "        train_scheduler.step()\n",
    "\n",
    "        total_num += batch_size\n",
    "        total_loss += loss.item() * batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n",
    "\n",
    "\n",
    "# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n",
    "def test(net, memory_data_loader, test_data_loader, temperature):\n",
    "    net.eval()\n",
    "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "    with torch.no_grad():\n",
    "        # generate feature bank\n",
    "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
    "            feature, out = net(data.cuda(non_blocking=True))\n",
    "            feature_bank.append(feature)\n",
    "        # [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        # [N]\n",
    "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
    "        # loop test data to predict the label by weighted knn search\n",
    "        test_bar = tqdm(test_data_loader)\n",
    "        for data, _, target in test_bar:\n",
    "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
    "            feature, out = net(data)\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "            sim_matrix = torch.mm(feature, feature_bank)\n",
    "            # [B, K]\n",
    "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
    "            # [B, K]\n",
    "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
    "            sim_weight = (sim_weight / temperature).exp()\n",
    "\n",
    "            # counts for each class\n",
    "            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n",
    "            # [B*K, C]\n",
    "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "            # weighted score ---> [B, C]\n",
    "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "\n",
    "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
    "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
    "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
    "\n",
    "    return total_top1 / total_num * 100, total_top5 / total_num * 100\n",
    "\n",
    "\n",
    "#Loading AID Dataset\n",
    "#Acknowledgements add later\n",
    "#Assume current working directory is '/home/umaiyal/CS5260Project'\n",
    "data_folder=os.path.join('CMC_RSSR_main','data','AID')\n",
    "datalist_folder=os.path.join('CMC_RSSR_main','data_splits')\n",
    "trn_list=os.path.join(datalist_folder,'AID_train.txt')\n",
    "test_list=os.path.join(datalist_folder,'AID_val.txt')\n",
    "\n",
    "#if (cropsize>32|batch_size<128):\n",
    "numworkersset=0\n",
    "#else:\n",
    "#numworkersset=16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umaiyal/miniconda3/envs/deeplearn_course/lib/python3.7/site-packages/thop/vision/basic_hooks.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  kernel = torch.DoubleTensor([*(x[0].shape[2:])]) // torch.DoubleTensor(list((m.output_size,))).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "# Model Params: 24.62M FLOPs: 4.00G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: [1/500] Loss: 5.1965: 100%|██████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.176844693055945e-05\n",
      "tensor(5.1965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [1/500] Acc@1:23.82% Acc@5:61.54%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [2/500] Loss: 5.0871: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.233370503562748e-05\n",
      "tensor(5.0926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [2/500] Acc@1:25.54% Acc@5:62.36%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [3/500] Loss: 4.9801: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.327552629165222e-05\n",
      "tensor(4.9857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [3/500] Acc@1:26.44% Acc@5:64.30%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [4/500] Loss: 4.8913: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.459349744696965e-05\n",
      "tensor(4.8960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [4/500] Acc@1:27.38% Acc@5:65.40%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [5/500] Loss: 4.8085: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.628704020312856e-05\n",
      "tensor(4.8129)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [5/500] Acc@1:27.64% Acc@5:66.46%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [6/500] Loss: 4.7304: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.835541146863608e-05\n",
      "tensor(4.7345)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [6/500] Acc@1:28.90% Acc@5:68.52%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [7/500] Loss: 4.6053: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.079770368501224e-05\n",
      "tensor(4.6118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [7/500] Acc@1:30.30% Acc@5:69.60%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [8/500] Loss: 4.6394: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.36128452250057e-05\n",
      "tensor(4.6381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [8/500] Acc@1:30.72% Acc@5:70.48%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [9/500] Loss: 4.4997: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.679960086280334e-05\n",
      "tensor(4.5066)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [9/500] Acc@1:30.78% Acc@5:70.72%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [10/500] Loss: 4.5050: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.035657231602095e-05\n",
      "tensor(4.5051)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [10/500] Acc@1:31.18% Acc@5:72.10%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [11/500] Loss: 4.4088: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.428219885924049e-05\n",
      "tensor(4.4136)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [11/500] Acc@1:30.86% Acc@5:72.30%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [12/500] Loss: 4.3647: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.85747580088249e-05\n",
      "tensor(4.3672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [12/500] Acc@1:31.80% Acc@5:73.28%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [13/500] Loss: 4.3261: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010323236627870721\n",
      "tensor(4.3282)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [13/500] Acc@1:32.30% Acc@5:74.36%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [14/500] Loss: 4.2747: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010825298000682556\n",
      "tensor(4.2774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [14/500] Acc@1:32.34% Acc@5:74.40%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [15/500] Loss: 4.2444: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011363439625184085\n",
      "tensor(4.2460)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [15/500] Acc@1:32.96% Acc@5:74.60%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [16/500] Loss: 4.2047: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011937425375973935\n",
      "tensor(4.2068)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [16/500] Acc@1:33.36% Acc@5:74.90%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [17/500] Loss: 4.1956: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00012547003399990524\n",
      "tensor(4.1962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [17/500] Acc@1:33.82% Acc@5:74.88%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [18/500] Loss: 4.1591: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001319190622701969\n",
      "tensor(4.1610)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [18/500] Acc@1:34.68% Acc@5:75.48%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [19/500] Loss: 4.1362: 100%|██████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013871850887055238\n",
      "tensor(4.1375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.06s/it]\n",
      "Test Epoch: [19/500] Acc@1:34.90% Acc@5:76.00%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [20/500] Loss: 4.0913: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00014586539034460257\n",
      "tensor(4.0936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [20/500] Acc@1:35.76% Acc@5:76.80%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [21/500] Loss: 4.0506: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001533565707887508\n",
      "tensor(4.0528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [21/500] Acc@1:35.28% Acc@5:75.64%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [22/500] Loss: 4.0255: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016118876322814154\n",
      "tensor(4.0269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [22/500] Acc@1:33.86% Acc@5:74.56%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [23/500] Loss: 3.9577: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016935853105891677\n",
      "tensor(3.9611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [23/500] Acc@1:36.04% Acc@5:76.26%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [24/500] Loss: 3.9289: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00017786228955612754\n",
      "tensor(3.9305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [24/500] Acc@1:36.06% Acc@5:77.02%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [25/500] Loss: 3.9229: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018669630744663703\n",
      "tensor(3.9233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [25/500] Acc@1:37.96% Acc@5:77.38%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [26/500] Loss: 3.9466: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019585670854632416\n",
      "tensor(3.9454)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [26/500] Acc@1:37.24% Acc@5:78.06%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [27/500] Loss: 3.8349: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020533947346087589\n",
      "tensor(3.8404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [27/500] Acc@1:37.14% Acc@5:76.00%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [28/500] Loss: 3.7974: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021514044134941096\n",
      "tensor(3.7995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [28/500] Acc@1:34.22% Acc@5:72.86%: 100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n",
      "Train Epoch: [29/500] Loss: 3.7152: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00022525531175017358\n",
      "tensor(3.7194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [29/500] Acc@1:38.10% Acc@5:77.02%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [30/500] Loss: 3.6986: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00023567964646748494\n",
      "tensor(3.6997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [30/500] Acc@1:38.52% Acc@5:77.30%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [31/500] Loss: 3.6073: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024640887151913273\n",
      "tensor(3.6119)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [31/500] Acc@1:34.96% Acc@5:74.08%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [32/500] Loss: 3.5340: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002574382791433391\n",
      "tensor(3.5379)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [32/500] Acc@1:34.76% Acc@5:72.82%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [33/500] Loss: 3.4631: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002687630298644297\n",
      "tensor(3.4668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [33/500] Acc@1:41.44% Acc@5:78.36%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [34/500] Loss: 3.4242: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002803781546162948\n",
      "tensor(3.4263)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [34/500] Acc@1:43.10% Acc@5:79.92%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [35/500] Loss: 3.2782: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002922785569227132\n",
      "tensor(3.2856)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [35/500] Acc@1:40.34% Acc@5:78.40%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [36/500] Loss: 3.1701: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00030445901513358035\n",
      "tensor(3.1758)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.03s/it]\n",
      "Test Epoch: [36/500] Acc@1:38.32% Acc@5:76.54%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [37/500] Loss: 3.1333: 100%|██████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003169141847160588\n",
      "tensor(3.1355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [37/500] Acc@1:40.54% Acc@5:78.76%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [38/500] Loss: 3.0991: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032963860059965133\n",
      "tensor(3.1009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [38/500] Acc@1:39.52% Acc@5:78.42%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [39/500] Loss: 2.8585: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003426266795741582\n",
      "tensor(2.8706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [39/500] Acc@1:36.44% Acc@5:74.88%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [40/500] Loss: 2.8215: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003558727227394758\n",
      "tensor(2.8240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [40/500] Acc@1:35.12% Acc@5:76.16%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [41/500] Loss: 2.7314: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003693709180061552\n",
      "tensor(2.7360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [41/500] Acc@1:39.48% Acc@5:78.94%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [42/500] Loss: 2.6711: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00038311534264562634\n",
      "tensor(2.6744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [42/500] Acc@1:30.48% Acc@5:70.86%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [43/500] Loss: 2.6615: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00039709996588896987\n",
      "tensor(2.6622)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [43/500] Acc@1:33.92% Acc@5:73.42%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [44/500] Loss: 2.5012: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004113186515730927\n",
      "tensor(2.5093)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [44/500] Acc@1:33.24% Acc@5:73.40%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [45/500] Loss: 2.4572: 100%|██████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00042576516083314936\n",
      "tensor(2.4598)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [45/500] Acc@1:35.20% Acc@5:73.82%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [46/500] Loss: 2.3601: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004404331548400269\n",
      "tensor(2.3651)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [46/500] Acc@1:37.30% Acc@5:77.46%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [47/500] Loss: 2.2504: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004553161975816924\n",
      "tensor(2.2561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [47/500] Acc@1:34.80% Acc@5:72.64%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [48/500] Loss: 2.3269: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004704077586871805\n",
      "tensor(2.3233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [48/500] Acc@1:25.48% Acc@5:64.44%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [49/500] Loss: 2.4141: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004857012162919861\n",
      "tensor(2.4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [49/500] Acc@1:35.80% Acc@5:75.62%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [50/500] Loss: 2.1598: 100%|██████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005011898599436013\n",
      "tensor(2.1723)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [50/500] Acc@1:29.68% Acc@5:70.08%: 100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n",
      "Train Epoch: [51/500] Loss: 2.1570: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005168668935459217\n",
      "tensor(2.1578)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [51/500] Acc@1:27.06% Acc@5:65.54%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [52/500] Loss: 2.2853: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005327254383412344\n",
      "tensor(2.2789)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [52/500] Acc@1:32.14% Acc@5:72.24%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [53/500] Loss: 2.1394: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005487585359284734\n",
      "tensor(2.1464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [53/500] Acc@1:36.76% Acc@5:77.38%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [54/500] Loss: 2.1589: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005649591513164224\n",
      "tensor(2.1582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [54/500] Acc@1:30.24% Acc@5:68.40%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [55/500] Loss: 1.9677: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005813201760105223\n",
      "tensor(1.9772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [55/500] Acc@1:33.44% Acc@5:74.18%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [56/500] Loss: 1.8866: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005978344311319331\n",
      "tensor(1.8911)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [56/500] Acc@1:34.62% Acc@5:74.68%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [57/500] Loss: 1.8538: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006144946705674754\n",
      "tensor(1.8556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [57/500] Acc@1:34.06% Acc@5:73.44%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [58/500] Loss: 1.8121: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006312935841490763\n",
      "tensor(1.8143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [58/500] Acc@1:28.02% Acc@5:66.58%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [59/500] Loss: 1.7575: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006482238008613192\n",
      "tensor(1.7603)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [59/500] Acc@1:28.70% Acc@5:66.88%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [60/500] Loss: 1.7919: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006652778920756923\n",
      "tensor(1.7903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [60/500] Acc@1:34.32% Acc@5:74.42%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [61/500] Loss: 1.7031: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000682448374810118\n",
      "tensor(1.7075)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [61/500] Acc@1:32.54% Acc@5:72.16%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [62/500] Loss: 1.7805: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006997277150123291\n",
      "tensor(1.7768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [62/500] Acc@1:32.18% Acc@5:72.50%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [63/500] Loss: 1.7226: 100%|██████████| 40/40 [01:06<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007171083308656564\n",
      "tensor(1.7253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [63/500] Acc@1:28.48% Acc@5:68.30%: 100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n",
      "Train Epoch: [64/500] Loss: 1.6659: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007345825961157721\n",
      "tensor(1.6689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "Test Epoch: [64/500] Acc@1:51.22% Acc@5:87.50%: 100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n",
      "Train Epoch: [65/500] Loss: 1.7435: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007521428434169317\n",
      "tensor(1.7398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [65/500] Acc@1:28.66% Acc@5:67.94%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [66/500] Loss: 1.6534: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000769781367696248\n",
      "tensor(1.6577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [66/500] Acc@1:44.04% Acc@5:83.86%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [67/500] Loss: 1.6519: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007874904295345159\n",
      "tensor(1.6522)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [67/500] Acc@1:27.06% Acc@5:66.78%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [68/500] Loss: 1.8119: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008052622585621105\n",
      "tensor(1.8039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [68/500] Acc@1:38.84% Acc@5:78.82%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [69/500] Loss: 1.6902: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008230890568684644\n",
      "tensor(1.6959)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:42<00:00,  1.06s/it]\n",
      "Test Epoch: [69/500] Acc@1:27.54% Acc@5:65.74%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [70/500] Loss: 1.6682: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008409630024236279\n",
      "tensor(1.6695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [70/500] Acc@1:33.68% Acc@5:75.36%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [71/500] Loss: 1.5684: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008588762525104161\n",
      "tensor(1.5735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [71/500] Acc@1:30.10% Acc@5:68.34%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [72/500] Loss: 1.5276: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008768209471656282\n",
      "tensor(1.5299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [72/500] Acc@1:30.14% Acc@5:70.46%: 100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\n",
      "Train Epoch: [73/500] Loss: 1.5317: 100%|██████████| 40/40 [01:06<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008947892126288387\n",
      "tensor(1.5316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "Test Epoch: [73/500] Acc@1:37.30% Acc@5:78.42%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [74/500] Loss: 1.5008: 100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009127731647972397\n",
      "tensor(1.5023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extracting: 100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "Test Epoch: [74/500] Acc@1:32.44% Acc@5:73.38%: 100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n",
      "Train Epoch: [75/500] Loss: 1.4963:  92%|█████████▎| 37/40 [01:02<00:05,  1.67s/it]"
     ]
    }
   ],
   "source": [
    "# Train SimCLR\n",
    "import numpy as np\n",
    "   \n",
    "# Feature dim for latent vector, Temperature used in softmax, Top k most similar images used to predict the label\n",
    "feature_dim, temp, k = 128, [0.1], 200\n",
    "# Number of images in each mini-batch, Number of sweeps over the dataset to train\n",
    "batch_size=128\n",
    "#Coarse setting\n",
    "#Fine setting\n",
    "lr_start = 0.00025\n",
    "lr_end =0.398\n",
    "max_lrvalue=0.0017895 #Rule of Thumb is peaklr (from lambdalr test)*3/8\n",
    "temp0 = 0.1 #contrastive loss temperature setting\n",
    "schedulertype='onecyclelr' #'lambdalr' for testing range of training or 'onecyclelr' for actual training\n",
    "if schedulertype=='lambdalr':\n",
    "    epochs=10\n",
    "    #epochs=10 #coarserg recommend 10 epochs, finerg recommend 100 epochs \n",
    "elif schedulertype=='onecyclelr':\n",
    "    epochs=500\n",
    "    #epochs=3\n",
    "else:\n",
    "    print('choose valid option for scheduler')\n",
    "smoothfactor=0.95 #Smooth Factor for smoothing contrastive loss    \n",
    "IterationStr='It1'\n",
    "loadmodel=0 #loadmodel=0 From scratch or loadmodel=1 Continue from presaved model \n",
    "pathtosave='/home/umaiyal/CS5260Project/results/Simclr_resnet50_AID_RAdamv2'+schedulertype+'/'+IterationStr+'/'\n",
    "save_name_pre = '{}_{}_{}_{}_{}'.format(feature_dim, temp0, k, batch_size, epochs)\n",
    "csvfilename=pathtosave+'{}_statistics.csv'.format(save_name_pre)\n",
    "modelfilename=pathtosave+'{}_model.pth'.format(save_name_pre)\n",
    "\n",
    "# data prepare\n",
    "train_data=ClassificationImageDatasetPair(data_folder, trn_list, transform=train_transform)\n",
    "train_loader=torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, \n",
    "                                         num_workers=numworkersset, pin_memory=True, sampler=None)\n",
    "memory_data=ClassificationImageDatasetPair(data_folder, trn_list, transform=test_transform)\n",
    "memory_loader = torch.utils.data.DataLoader(memory_data, batch_size=batch_size, shuffle=False, \n",
    "                                         num_workers=numworkersset, pin_memory=True, sampler=None)\n",
    "test_data=ClassificationImageDatasetPair(data_folder,test_list,transform=test_transform)\n",
    "test_loader=torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, \n",
    "                                         num_workers=numworkersset, pin_memory=True, sampler=None)\n",
    "import torch\n",
    "n=3\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(n)\n",
    "\n",
    "# model setup and optimizer config\n",
    "model = Model(feature_dim).cuda(n)\n",
    "\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, cropsize, cropsize).cuda(n),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
    "\n",
    "optimizer = optim.RAdam(model.parameters(), lr=1.0)\n",
    "#optimizer=optim.Adam(model.parameters(),lr=1.0)\n",
    "\n",
    "#exponentially increase learning rate from low to high\n",
    "def lrs(batch):\n",
    "   low = math.log2(lr_start)\n",
    "   high = math.log2(lr_end)\n",
    "   return 2**(low+(high-low)*batch/len(train_loader)/epochs)\n",
    "   \n",
    "if schedulertype=='lambdalr':\n",
    "   scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lrs)\n",
    "elif schedulertype=='onecyclelr':\n",
    "   scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=max_lrvalue,total_steps=len(train_loader)*epochs,epochs=epochs)\n",
    "else:\n",
    "   print('choose valid option for scheduler')\n",
    "\n",
    "if loadmodel==1:\n",
    "   checkpoint=torch.load(modelfilename)\n",
    "   model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "   model.to(device)\n",
    "   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "   scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "   startepoch=checkpoint['epoch']+1\n",
    "   best_acc=checkpoint['best_acc']\n",
    "\n",
    "   print(startepoch)\n",
    "else:     \n",
    "   startepoch=1\n",
    "   best_acc=0\n",
    "   \n",
    "\n",
    "c = len(memory_data.classes)\n",
    "\n",
    "if not os.path.exists(pathtosave):\n",
    "   os.makedirs(pathtosave)\n",
    "\n",
    "train_loss_epoch=torch.zeros(epochs)\n",
    "smooth_loss_epoch=torch.zeros(epochs)\n",
    "test_acc_1_epoch=torch.zeros(epochs)\n",
    "test_acc_5_epoch=torch.zeros(epochs)\n",
    "lr_epoch=torch.zeros(epochs)\n",
    "if loadmodel==1:\n",
    "   df=pd.read_csv(csvfilename)\n",
    "   temp=pd.to_numeric(df['train_loss']).apply(np.array)\n",
    "   train_loss_epoch[0:temp.size]=torch.tensor(temp)\n",
    "   train_loss_list=temp.tolist()\n",
    "   temp=pd.to_numeric(df['smooth_loss']).apply(np.array)\n",
    "   smooth_loss_epoch[0:temp.size]=torch.tensor(temp)\n",
    "   smooth_loss_list=temp.tolist()\n",
    "   temp=pd.to_numeric(df['test_acc@1']).apply(np.array)\n",
    "   test_acc_1_epoch[0:temp.size]=torch.tensor(temp)\n",
    "   test_acc_1_list=temp.tolist()\n",
    "   temp=pd.to_numeric(df['test_acc@5']).apply(np.array)\n",
    "   test_acc_5_epoch[0:temp.size]=torch.tensor(temp)\n",
    "   test_acc_5_list=temp.tolist()\n",
    "   temp=pd.to_numeric(df['lr_epoch']).apply(np.array)\n",
    "   lr_epoch[0:temp.size]=torch.tensor(temp)\n",
    "   lr_list=temp.tolist()\n",
    "   results = {'train_loss': train_loss_list, 'test_acc@1': test_acc_1_list, 'test_acc@5': test_acc_5_list, 'smooth_loss': smooth_loss_list, 'lr_epoch': lr_list}\n",
    "\n",
    "else:\n",
    "   results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': [], 'smooth_loss': [], 'lr_epoch': []}\n",
    "\n",
    "\n",
    "for epoch in range(startepoch, epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, scheduler, temp0)\n",
    "    train_loss_epoch[epoch-1]=train_loss\n",
    "    if epoch>1:\n",
    "       smooth_loss=float(train_loss_epoch[epoch-1]*smoothfactor+smooth_loss_epoch[epoch-2]*(1.0-smoothfactor))\n",
    "    else:\n",
    "       smooth_loss=train_loss\n",
    "    smooth_loss_epoch[epoch-1]=torch.tensor(smooth_loss)\n",
    "\n",
    "\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    print(smooth_loss_epoch[epoch-1])\n",
    "    lr_epoch[epoch-1]=float(optimizer.param_groups[0]['lr'])\n",
    "   \n",
    "        \n",
    "    results['train_loss'].append(train_loss)\n",
    "    test_acc_1, test_acc_5 = test(model, memory_loader, test_loader, temp0)\n",
    "    results['test_acc@1'].append(test_acc_1)\n",
    "    results['test_acc@5'].append(test_acc_5)\n",
    "    results['smooth_loss'].append(smooth_loss)\n",
    "    results['lr_epoch'].append(optimizer.param_groups[0]['lr'])\n",
    "    # save statistics\n",
    "    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
    "    data_frame.to_csv(csvfilename, index_label='epoch')\n",
    "    if test_acc_1 > best_acc:\n",
    "        best_acc = test_acc_1\n",
    "        torch.save({'epoch':epoch,'model_state_dict':model.state_dict(),'optimizer_state_dict':optimizer.state_dict(),'scheduler_state_dict':scheduler.state_dict(),'best_acc':best_acc}, modelfilename)\n",
    "    test_acc_1_epoch[epoch-1]=test_acc_1\n",
    "    test_acc_5_epoch[epoch-1]=test_acc_5\n",
    "    \n",
    "minloss_loc=torch.argmin(smooth_loss_epoch)\n",
    "minloss_loclr=lr_epoch[minloss_loc]\n",
    "print(f'lr corresponding to minloss={minloss_loclr}');\n",
    "print(f'suggested maxlr={minloss_loclr*3/8}');\n",
    "print(f'suggested minlr={minloss_loclr*3/80}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(csvfilename)\n",
    "\n",
    "f1=plt.figure()\n",
    "plt.semilogx(df['lr_epoch'],df['smooth_loss'])  \n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('smoothed trg epoch loss')\n",
    "plt.show()\n",
    "\n",
    "f2=plt.figure()\n",
    "plt.plot(df['test_acc@1'])\n",
    "plt.title('Sim CLR with AdamW')\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('epoch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "simclr_resnet50_lamb_500_AID.ipynb",
   "provenance": [
    {
     "file_id": "1y9-JHm2CoprtTIq-j22CBgPVNQtVMIv5",
     "timestamp": 1649176146143
    },
    {
     "file_id": "1rpL0kWCS3tnRWhVwbTprikpntGfbb9zP",
     "timestamp": 1648871423849
    },
    {
     "file_id": "1DVxLFzytRmpwMGdm4PiZM2GUh6B0IjM-",
     "timestamp": 1647967194085
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
